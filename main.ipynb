{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# automatically upload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import ray\n",
    "from ray import tune\n",
    "from scipy import stats\n",
    "import sklearn as sk\n",
    "import torch\n",
    "\n",
    "from genome_embeddings import corrupt\n",
    "from genome_embeddings import data_viz\n",
    "from genome_embeddings import evaluate\n",
    "from genome_embeddings import models\n",
    "from genome_embeddings import pathways\n",
    "from genome_embeddings import pre_process\n",
    "from genome_embeddings import trainable # import before ray (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = \"Desktop\" # \"CC\" | \"Desktop\"\n",
    "# must change local_dir=\"/Users/natasha/Desktop/TUNE_RESULT_DIR\"\n",
    "#local_dir=\"/home/ndudek/projects/def-dprecup/ndudek/hp_tuning_04-12-2020/TUNE_RESULT_DIR\"\n",
    "\n",
    "BASE_DIR = '/Users/natasha/Desktop/vae/'\n",
    "#BASE_DIR =\"/home/ndudek/projects/def-dprecup/ndudek/hp_tuning_04-12-2020/TUNE_RESULT_DIR\"\n",
    "\n",
    "if mode == \"Desktop\":\n",
    "    settings = Namespace(\n",
    "        DATA_FP = '/Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/data/', \n",
    "        SAVE_FP = '/Users/natasha/Desktop/',\n",
    "        num_epochs = 2,\n",
    "        num_cpus=5, \n",
    "        replacement_threshold = 0.5, # probability over which binarizer converts to a 1\n",
    "        num_corruptions = 100, # number of corrupted versions of a genome to produce\n",
    "    )\n",
    "elif mode == \"CC\":\n",
    "    settings = Namespace(\n",
    "        DATA_FP = '/home/ndudek/projects/def-dprecup/ndudek/hp_tuning_04-12-2020/',\n",
    "        SAVE_FP = '/home/ndudek/projects/def-dprecup/ndudek/hp_tuning_04-12-2020/',\n",
    "        num_epochs = 2,\n",
    "        num_cpus=5, \n",
    "        replacement_threshold = 0.5, # probability over which binarizer converts to a 1\n",
    "        num_corruptions = 100, # number of corrupted versions of a genome to produce\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of bacterial genomes in dataset: 2718\n",
      "Total number of KOs in dataset: 9874\n"
     ]
    }
   ],
   "source": [
    "tla_to_tnum, keepers = pre_process.genomes2include(mode)\n",
    "tnum_to_tla = {v:k for k,v in tla_to_tnum.items()}\n",
    "org_to_kos, n_kos_tot, all_kos = pre_process.load_kos(tla_to_tnum, mode)\n",
    "org_to_mod_to_kos, mod_sets = pre_process.load_mods(mode)\n",
    "mod_to_kos = pre_process.create_mod_to_kos(org_to_mod_to_kos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data needed to make corrupted train + test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of bacterial genomes in dataset: 2718\n"
     ]
    }
   ],
   "source": [
    "tla_to_tnum, keepers = pre_process.genomes2include(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of bacterial genomes in dataset: 2718\n",
      "Total number of KOs in dataset: 9874\n"
     ]
    }
   ],
   "source": [
    "create_new = False\n",
    "from_scratch = False # controls where in creation process to jump in\n",
    "\n",
    "# Create list of which genomes from KEGG to include in dataset\n",
    "tla_to_tnum, keepers = pre_process.genomes2include(mode)\n",
    "tnum_to_tla = {v:k for k,v in tla_to_tnum.items()}\n",
    "org_to_kos, n_kos_tot, all_kos = pre_process.load_kos(tla_to_tnum, mode)\n",
    "org_to_mod_to_kos, mod_sets = pre_process.load_mods(mode)\n",
    "mod_to_kos = pre_process.create_mod_to_kos(org_to_mod_to_kos)\n",
    "\n",
    "if create_new:\n",
    "    if from_scratch:\n",
    "        # Load list mods and KOs per genome\n",
    "        data, genome_order = pre_process.make_tensor(org_to_mod_to_kos, org_to_kos, n_kos_tot, tla_to_tnum, all_kos)\n",
    "        torch.save(data, BASE_DIR+\"kegg_v2.pt\")\n",
    "        torch.save(genome_order, BASE_DIR+\"genome_order.pt\")\n",
    "    else:\n",
    "        # load data -- tensor (genomes + which KOs are encoded) + genome_order in tensor (tla)\n",
    "        data = torch.load(BASE_DIR+\"kegg_v2.pt\")\n",
    "        genome_order = torch.load(BASE_DIR+\"genome_order.pt\")\n",
    "    \n",
    "    # Create test-train split\n",
    "    train_genomes, test_genomes = pre_process.train_test_split(keepers) # list of IDs to keep\n",
    "    train_data = pre_process.prep_data(train_genomes, all_kos, org_to_kos, \"train\")\n",
    "    test_data = pre_process.prep_data(test_genomes, all_kos, org_to_kos, \"test\")\n",
    "    \n",
    "    torch.save(all_kos, BASE_DIR+\"all_kos_2020-09-29.pt\")\n",
    "    torch.save(org_to_mod_to_kos, BASE_DIR+\"org_to_mod_to_kos_2020-09-29.pt\")\n",
    "    torch.save(train_data, BASE_DIR+\"kegg_v2_train_2020-09-29.pt\")\n",
    "    torch.save(test_data, BASE_DIR+\"kegg_v2_test_2020-09-29.pt\")\n",
    "    torch.save(train_genomes, BASE_DIR+\"kegg_v2_train_genomes_2020-09-29.pt\")\n",
    "    torch.save(test_genomes, BASE_DIR+\"kegg_v2_test_genomes_2020-09-29.pt\")\n",
    "else:\n",
    "    all_kos = torch.load(BASE_DIR+\"all_kos_2020-09-29.pt\")\n",
    "    org_to_mod_to_kos = torch.load(BASE_DIR+\"org_to_mod_to_kos_2020-09-29.pt\")\n",
    "    train_data = torch.load(BASE_DIR+\"kegg_v2_train_2020-09-29.pt\")\n",
    "    test_data = torch.load(BASE_DIR+\"kegg_v2_test_2020-09-29.pt\")\n",
    "    train_genomes = torch.load(BASE_DIR+\"kegg_v2_train_genomes_2020-09-29.pt\")\n",
    "    test_genomes = torch.load(BASE_DIR+\"kegg_v2_test_genomes_2020-09-29.pt\")\n",
    "\n",
    "mod_to_ko_clean = pre_process.clean_kos(mod_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2430, 9874)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any genomes with fewer than n_min KOs (endosymbionts)\n",
    "n_min = 500\n",
    "good_idx_train = train_data.sum(axis=1) >= n_min\n",
    "good_idx_test = test_data.sum(axis=1) >= n_min\n",
    "train_data = train_data[good_idx_train,:]\n",
    "test_data = test_data[good_idx_test,:]\n",
    "\n",
    "# to numpy for indexing, then back to list for using\n",
    "train_genomes = list(np.array(train_genomes)[good_idx_train])\n",
    "test_genomes = list(np.array(test_genomes)[good_idx_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of genomes that encode fewer than n_mods modules\n",
    "n_mods = 10\n",
    "train_data, train_genomes = pre_process.remove_duds(train_data, train_genomes, tnum_to_tla, org_to_mod_to_kos, n_mods)\n",
    "test_data, test_genomes = pre_process.remove_duds(test_data, test_genomes, tnum_to_tla, org_to_mod_to_kos, n_mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there any columns that are all zeros in both the train and test sets (TL;DR yes)\n",
    "good_cols = ((train_data.sum(axis=0) != 0) | (test_data.sum(axis=0) != 0))\n",
    "train_data = train_data[:,good_cols]\n",
    "test_data = test_data[:,good_cols]\n",
    "all_kos = np.array(all_kos)[good_cols].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 77)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data.sum(axis=1) == 0).sum(), (train_data.sum(axis=0) == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1595)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_data.sum(axis=1) == 0).sum(), (test_data.sum(axis=0) == 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2305, 9863), (279, 9863), 2584)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape, train_data.shape[0]+test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2584"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[0] + test_data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = 'M00001'\n",
    "a = list(mod_sets[mod].values())\n",
    "a.sort(reverse=True)\n",
    "x_labels = [i for i in range(len(mod_sets[mod].values()))]\n",
    "plt.bar(x_labels, a)\n",
    "plt.yscale('log')\n",
    "plt.title(\"Variants of module \"+mod)\n",
    "plt.xlabel(\"Variant (n=\"+str(len(mod_sets[mod].values()))+\" )\")\n",
    "plt.ylabel(\"Count across all genomes (n=\"+str(len(org_to_mod_to_kos))+\")\")\n",
    "print(max(mod_sets[mod].values()), len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of KOs encoded by each genome\n",
    "# Note: this includes genomes excluded from the final dataset!\n",
    "plt.hist([len(org_to_kos[i]) for i in org_to_kos], 50)\n",
    "plt.xlabel(\"Number of KOs per genome\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(BASE_DIR+\"fig.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median, min, and max # KOs per genome\n",
    "lens = [len(org_to_kos[i]) for i in org_to_kos if i in train_genomes or i in test_genomes]\n",
    "print(np.median(lens), min(lens), max(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the number of modules encoded by each genome\n",
    "n_genomes = len(org_to_mod_to_kos)\n",
    "temp = [list(org_to_mod_to_kos[i].keys()) for i in org_to_mod_to_kos]\n",
    "n_mods_ = len(list(set([item for sublist in temp for item in sublist])))\n",
    "plt.hist([len(org_to_mod_to_kos[i]) for i in org_to_mod_to_kos], 50)\n",
    "plt.xlabel(\"Number of modules per genome\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of the # of modules (n=\"+str(n_mods_)+\") per genome (n=\"+str(n_genomes)+\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [len(org_to_mod_to_kos[org]) for org in org_to_mod_to_kos]\n",
    "# a.sort()\n",
    "# print(\"There are \"+str(a.count(0))+\" genomes with zero modules\")\n",
    "\n",
    "# # Red\n",
    "# # Rue\n",
    "# # pvac\n",
    "# # cgw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE THAT SOME GENOMES DO NOT HAVE A SINGLE MOD AND AREN'T EVEN IN THE DICT (n= 2717-2713 = 5)\n",
    "# E.G.: clap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Count and plot the number of genomes that encode each module\n",
    "# mods_count = defaultdict(int)\n",
    "# for org in org_to_mod_to_kos:\n",
    "#     for mod in org_to_mod_to_kos[org]:\n",
    "#         mods_count[mod] += 1\n",
    "        \n",
    "# plt.hist(mods_count.values(), 50)\n",
    "# plt.xlabel(\"Number of genomes encoding each module\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Distribution of the # of genomes (n=\"+str(n_genomes)+\") encoding each module (n=\"+str(n_mods)+\")\")\n",
    "# plt.yscale('log')\n",
    "# print(\"Number of mods encoded in only one genome:\",list(mods_count.values()).count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the percentage of genes per genome that contribute to modules\n",
    "# perc_mod = []\n",
    "# for org in org_to_mod_to_kos:\n",
    "#     try:\n",
    "#         tla = tla_to_tnum[org]\n",
    "#         n_kos = len(org_to_kos[tla])\n",
    "#         n_mod_kos = len([org_to_mod_to_kos[org][mod] for mod in org_to_mod_to_kos[org]])\n",
    "#         perc_mod.append(n_mod_kos/n_kos*100)\n",
    "#     except: KeyError\n",
    "\n",
    "# plt.hist(perc_mod, 50)\n",
    "# plt.xlabel(\"Percent of KOs contributing to modules\")\n",
    "# plt.ylabel(\"Frequency\")\n",
    "# plt.title(\"Distribution of the % of KOs (n_all=\"+str(n_kos_tot)+\") represented by modules (n=\"+str(n_mods)+\") per genome (n=\"+str(n_genomes)+\")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Percentage of KOs that are / are not part of a module\n",
    "\n",
    "# kos_in_mods = []\n",
    "\n",
    "# for org in org_to_mod_to_kos:\n",
    "#     for mod in org_to_mod_to_kos[org]:\n",
    "#         kos_in_mods.extend(org_to_mod_to_kos[org][mod])\n",
    "\n",
    "# kos_in_mods = list(set(kos_in_mods))\n",
    "\n",
    "# print(len(kos_in_mods), len(all_kos), len(kos_in_mods)/len(all_kos)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Number of KOs that are part of 1 module, 2 modules, 3 modules, etc\n",
    "# #all_kos # unique list of all KOs\n",
    "# ko_counter = defaultdict(list)\n",
    "\n",
    "# for ko in all_kos:\n",
    "#     for org in org_to_mod_to_kos:\n",
    "#         for mod in org_to_mod_to_kos[org]:\n",
    "#             if ko in org_to_mod_to_kos[org][mod]:\n",
    "#                 if mod not in ko_counter[ko]:\n",
    "#                     ko_counter[ko].append(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ko_counter2 = {}\n",
    "# for ko in ko_counter:\n",
    "#     ko_counter2[ko] = len(ko_counter[ko])\n",
    "\n",
    "# for ko in all_kos:\n",
    "#     if ko not in ko_counter2:\n",
    "#         ko_counter2[ko] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = defaultdict(int)\n",
    "# for i in ko_counter2.values():\n",
    "#     a[i] += 1\n",
    "# a, sum(a.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(ko_counter2.values())\n",
    "# plt.yscale('log')\n",
    "# plt.title(\"Number of modules each KO contributes to\")\n",
    "# plt.xlabel(\"Number of modules\")\n",
    "# plt.ylabel(\"Frequency (# of KOs)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corrupt input genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2021-01-05_10mods\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# corrupt version 1 -- extreme corruption\n",
    "# 2020-09-04: select 1-10 mods for input\n",
    "# 2020-10-16_10mods: select 10 mods for input, genomes with fewer than 10 mods are eliminated\n",
    "# 2020-10-16_1mods: select 1 mods for input, genomes with fewer than 10 mods are eliminated \n",
    "\n",
    "new_corrupt = False\n",
    "n_corrupt = 100\n",
    "date_to_save = \"2021-01-05_\"+str(n_mods)+\"mods\"\n",
    "date_to_load = \"2021-01-05_10mods\"\n",
    "\n",
    "tnum_to_tla = {v:k for k,v in tla_to_tnum.items()}\n",
    "\n",
    "if new_corrupt:\n",
    "    print (\"Creating new corruptions\")\n",
    "    print (str(n_corrupt),\"corruptions per genome\")\n",
    "    print (\"With\",str(n_mods),\"modules as input per genome\")\n",
    "    print (\"Saved as\",date_to_save)\n",
    "    #tnum_to_tla = {v:k for k,v in tla_to_tnum.items()}\n",
    "    corrupted_train, c_train_genomes, train_input_mods = corrupt.corrupt(train_data, train_genomes, n_corrupt, tnum_to_tla, org_to_mod_to_kos, all_kos, mod_to_ko_clean, org_to_kos, n_mods)\n",
    "    corrupted_test, c_test_genomes, test_input_mods = corrupt.corrupt(test_data, test_genomes, n_corrupt, tnum_to_tla, org_to_mod_to_kos, all_kos, mod_to_ko_clean, org_to_kos, n_mods)\n",
    "    torch.save(corrupted_train, BASE_DIR+\"corrupted_train_\"+date_to_save+\".pt\")\n",
    "    torch.save(c_train_genomes, BASE_DIR+\"c_train_genomes_\"+date_to_save+\".pt\")\n",
    "    torch.save(corrupted_test, BASE_DIR+\"corrupted_test_\"+date_to_save+\".pt\")\n",
    "    torch.save(c_test_genomes, BASE_DIR+\"c_test_genomes_\"+date_to_save+\".pt\")\n",
    "    torch.save(train_input_mods, BASE_DIR+\"train_input_mods_\"+date_to_save+\".pt\")\n",
    "    torch.save(test_input_mods, BASE_DIR+\"test_input_mods_\"+date_to_save+\".pt\")\n",
    "else:\n",
    "    print(\"Loading \"+date_to_load)\n",
    "    corrupted_train = torch.load(BASE_DIR+\"corrupted_train_\"+date_to_load+\".pt\")\n",
    "    c_train_genomes = torch.load(BASE_DIR+\"c_train_genomes_\"+date_to_load+\".pt\")\n",
    "    corrupted_test = torch.load(BASE_DIR+\"corrupted_test_\"+date_to_load+\".pt\")\n",
    "    c_test_genomes = torch.load(BASE_DIR+\"c_test_genomes_\"+date_to_load+\".pt\")\n",
    "    train_input_mods = torch.load(BASE_DIR+\"train_input_mods_\"+date_to_load+\".pt\")\n",
    "    test_input_mods = torch.load(BASE_DIR+\"test_input_mods_\"+date_to_load+\".pt\")\n",
    "    \n",
    "print (\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230500, 230500)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confirm that there are no all-zero rows\n",
    "non_zero_idx = corrupted_train.sum(axis=1) > n_min\n",
    "len(non_zero_idx), corrupted_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([230500, 19726]), torch.Size([27900, 19726]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_train.shape, corrupted_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of final datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, labels, y3 = data_viz.plot_tax_dist(c_train_genomes, c_test_genomes, 'Desktop')\n",
    "plt.savefig(BASE_DIR+\"fig_dist.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lengths(c_genomes, org_to_kos):\n",
    "    lens = []\n",
    "    for i in list(set(c_genomes)):\n",
    "        tnum = tla_to_tnum[i]\n",
    "        lens.append(len(org_to_kos[tnum]))\n",
    "    return lens\n",
    "\n",
    "train_lens = get_lengths(c_train_genomes, org_to_kos)\n",
    "test_lens = get_lengths(c_test_genomes, org_to_kos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of KOs encoded by each genome\n",
    "fig, ax = plt.subplots()\n",
    "plt.hist(train_lens, 50, color='#3385ff')\n",
    "plt.hist(test_lens, 50, color='#bb99ff')\n",
    "ax.legend(['Train', 'Test'])\n",
    "plt.xlabel(\"# annotated genes / genome\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.ylim(0,125)\n",
    "plt.xlim(min(train_lens),max(train_lens)+10)\n",
    "plt.savefig(BASE_DIR+\"fig_ko_dist.pdf\", figsize=(370.336, 245.416), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many modules are there per training genome?\n",
    "from collections import defaultdict\n",
    "mods_count = defaultdict(int)\n",
    "for org in org_to_mod_to_kos:\n",
    "    if org in c_train_genomes:\n",
    "        mods_count[org] = len(org_to_mod_to_kos[org])\n",
    "plt.hist(mods_count.values())\n",
    "plt.xlabel('Number of modules')\n",
    "plt.ylabel('Number of genomes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HPO w/ Ray Tune: Define and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory = 2000 * 1024 * 1024\n",
    "object_store_memory = 200 * 1024 * 1024\n",
    "driver_object_store_memory=100 * 1024 * 1024\n",
    "ray.shutdown()\n",
    "ray.init(local_mode=True, memory=memory, \n",
    "        object_store_memory=object_store_memory,\n",
    "        driver_object_store_memory=driver_object_store_memory,\n",
    "        num_cpus=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"num_epochs\": 10,\n",
    "         \"kfolds\": 10,\n",
    "         \"replacement_threshold\": 0.5,\n",
    "         \"nn_layers\": tune.choice([1, 2, 3, 4]),\n",
    "         \"batch_size\": tune.choice([32, 64, 128, 256]),\n",
    "          \"lr\": tune.loguniform(1e-4, 1e-1), \n",
    "          \"weight_decay\": tune.loguniform(1e-5, 1e-2) \n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_corruption = {\"num_epochs\": 10,\n",
    "         \"kfolds\": 10,\n",
    "         \"replacement_threshold\": 0.5,\n",
    "         \"nn_layers\": 3,\n",
    "         \"batch_size\": 128,\n",
    "          \"lr\": 0.001, \n",
    "          \"weight_decay\": 0.1\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:06:33,723\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.59 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:06:33,727\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.59 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:06:33,728\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.59 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9574\n",
      "config[\"replacement_threshold\"] 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.12 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:06:47,222\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-06-47\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.4175658771214026\n",
      "  test_loss: tensor(5901444.)\n",
      "  time_since_restore: 13.386452913284302\n",
      "  time_this_iter_s: 13.386452913284302\n",
      "  time_total_s: 13.386452913284302\n",
      "  timestamp: 1613772407\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.26044937117725253\n",
      "  train_loss: 862428.0625\n",
      "  training_iteration: 1\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         13.3865</td><td style=\"text-align: right;\">     1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:07:13,514\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-07-13\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 2\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.7821556022495828\n",
      "  test_loss: tensor(1646944.5000)\n",
      "  time_since_restore: 39.678390979766846\n",
      "  time_this_iter_s: 26.291938066482544\n",
      "  time_total_s: 39.678390979766846\n",
      "  timestamp: 1613772433\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.7963656883571928\n",
      "  train_loss: 206039.71875\n",
      "  training_iteration: 2\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:07:39,386\tWARNING util.py:132 -- The `process_trial` operation took 25.871381282806396 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         39.6784</td><td style=\"text-align: right;\">     2</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:07:39,390\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:07:39,391\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-07-39\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 3\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.8187590374915448\n",
      "  test_loss: tensor(1431274.7500)\n",
      "  time_since_restore: 65.55283999443054\n",
      "  time_this_iter_s: 25.874449014663696\n",
      "  time_total_s: 65.55283999443054\n",
      "  timestamp: 1613772459\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8161399215348548\n",
      "  train_loss: 180292.8125\n",
      "  training_iteration: 3\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:08:05,836\tWARNING util.py:132 -- The `process_trial` operation took 26.444602012634277 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         65.5528</td><td style=\"text-align: right;\">     3</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:08:05,840\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-08-05\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 4\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.8358308929463275\n",
      "  test_loss: tensor(1302981.7500)\n",
      "  time_since_restore: 92.00297594070435\n",
      "  time_this_iter_s: 26.450135946273804\n",
      "  time_total_s: 92.00297594070435\n",
      "  timestamp: 1613772485\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8321076463060921\n",
      "  train_loss: 175634.953125\n",
      "  training_iteration: 4\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:08:31,844\tWARNING util.py:132 -- The `process_trial` operation took 26.002474546432495 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">          92.003</td><td style=\"text-align: right;\">     4</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:08:31,848\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-08-31\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 5\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.8476889968137343\n",
      "  test_loss: tensor(1221154.)\n",
      "  time_since_restore: 118.01060795783997\n",
      "  time_this_iter_s: 26.00763201713562\n",
      "  time_total_s: 118.01060795783997\n",
      "  timestamp: 1613772511\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8432223102844518\n",
      "  train_loss: 155898.484375\n",
      "  training_iteration: 5\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:08:57,952\tWARNING util.py:132 -- The `process_trial` operation took 26.102556943893433 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         118.011</td><td style=\"text-align: right;\">     5</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:08:57,955\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:08:57,955\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-08-57\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 6\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.8558133982835224\n",
      "  test_loss: tensor(1157569.7500)\n",
      "  time_since_restore: 144.1185450553894\n",
      "  time_this_iter_s: 26.10793709754944\n",
      "  time_total_s: 144.1185450553894\n",
      "  timestamp: 1613772537\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8621500568688778\n",
      "  train_loss: 141302.828125\n",
      "  training_iteration: 6\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:09:24,746\tWARNING util.py:132 -- The `process_trial` operation took 26.790091037750244 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         144.119</td><td style=\"text-align: right;\">     6</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:09:24,751\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-09-24\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 7\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.8681149702932\n",
      "  test_loss: tensor(1088555.)\n",
      "  time_since_restore: 170.91316080093384\n",
      "  time_this_iter_s: 26.794615745544434\n",
      "  time_total_s: 170.91316080093384\n",
      "  timestamp: 1613772564\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.865236120093664\n",
      "  train_loss: 143246.203125\n",
      "  training_iteration: 7\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:09:51,720\tWARNING util.py:132 -- The `process_trial` operation took 26.96825408935547 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         170.913</td><td style=\"text-align: right;\">     7</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:09:51,723\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-09-51\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 8\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.8725472071329143\n",
      "  test_loss: tensor(1043815.8125)\n",
      "  time_since_restore: 197.88685607910156\n",
      "  time_this_iter_s: 26.973695278167725\n",
      "  time_total_s: 197.88685607910156\n",
      "  timestamp: 1613772591\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8685089030066463\n",
      "  train_loss: 137605.6875\n",
      "  training_iteration: 8\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:10:18,517\tWARNING util.py:132 -- The `process_trial` operation took 26.793988943099976 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         197.887</td><td style=\"text-align: right;\">     8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:10:18,522\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:10:18,523\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-10-18\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 9\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.880125141381947\n",
      "  test_loss: tensor(995444.4375)\n",
      "  time_since_restore: 224.68451714515686\n",
      "  time_this_iter_s: 26.797661066055298\n",
      "  time_total_s: 224.68451714515686\n",
      "  timestamp: 1613772618\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8793845007092537\n",
      "  train_loss: 129684.390625\n",
      "  training_iteration: 9\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:10:45,665\tWARNING util.py:132 -- The `process_trial` operation took 27.14179301261902 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         224.685</td><td style=\"text-align: right;\">     9</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:10:45,668\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-10-45\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 10\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.8855452407778627\n",
      "  test_loss: tensor(965832.1250)\n",
      "  time_since_restore: 251.83229303359985\n",
      "  time_this_iter_s: 27.147775888442993\n",
      "  time_total_s: 251.83229303359985\n",
      "  timestamp: 1613772645\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8826378587923103\n",
      "  train_loss: 125160.3671875\n",
      "  training_iteration: 10\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:11:12,657\tWARNING util.py:132 -- The `process_trial` operation took 26.988362073898315 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         251.832</td><td style=\"text-align: right;\">    10</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:11:12,662\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.6 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-11-12\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 11\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.8905257107520499\n",
      "  test_loss: tensor(739300.8125)\n",
      "  time_since_restore: 278.8244569301605\n",
      "  time_this_iter_s: 26.99216389656067\n",
      "  time_total_s: 278.8244569301605\n",
      "  timestamp: 1613772672\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8941114717950291\n",
      "  train_loss: 117964.25\n",
      "  training_iteration: 11\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:11:38,406\tWARNING util.py:132 -- The `process_trial` operation took 25.743451833724976 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         278.824</td><td style=\"text-align: right;\">    11</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:11:38,410\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:11:38,411\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-11-38\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 12\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.8946814230480032\n",
      "  test_loss: tensor(884030.8125)\n",
      "  time_since_restore: 304.5730719566345\n",
      "  time_this_iter_s: 25.748615026474\n",
      "  time_total_s: 304.5730719566345\n",
      "  timestamp: 1613772698\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8980633471407997\n",
      "  train_loss: 112338.828125\n",
      "  training_iteration: 12\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:11:45,376\tWARNING util.py:132 -- The `process_trial` operation took 6.964585781097412 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         304.573</td><td style=\"text-align: right;\">    12</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:11:45,378\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-11-45\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 13\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.8953844936608972\n",
      "  test_loss: tensor(892361.0625)\n",
      "  time_since_restore: 311.54308009147644\n",
      "  time_this_iter_s: 6.970008134841919\n",
      "  time_total_s: 311.54308009147644\n",
      "  timestamp: 1613772705\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8919992014814206\n",
      "  train_loss: 116262.390625\n",
      "  training_iteration: 13\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:12:11,194\tWARNING util.py:132 -- The `process_trial` operation took 25.815047025680542 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         311.543</td><td style=\"text-align: right;\">    13</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:12:11,200\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-12-11\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 14\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.899283123281731\n",
      "  test_loss: tensor(857837.2500)\n",
      "  time_since_restore: 337.3610751628876\n",
      "  time_this_iter_s: 25.817995071411133\n",
      "  time_total_s: 337.3610751628876\n",
      "  timestamp: 1613772731\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.8962350099037318\n",
      "  train_loss: 110122.8984375\n",
      "  training_iteration: 14\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:12:37,426\tWARNING util.py:132 -- The `process_trial` operation took 26.225517749786377 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         337.361</td><td style=\"text-align: right;\">    14</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:12:37,430\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-12-37\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 15\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.902620365529133\n",
      "  test_loss: tensor(682101.1875)\n",
      "  time_since_restore: 363.5925328731537\n",
      "  time_this_iter_s: 26.231457710266113\n",
      "  time_total_s: 363.5925328731537\n",
      "  timestamp: 1613772757\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9069316554529961\n",
      "  train_loss: 101729.84375\n",
      "  training_iteration: 15\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:13:04,600\tWARNING util.py:132 -- The `process_trial` operation took 27.169312953948975 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         363.593</td><td style=\"text-align: right;\">    15</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:13:04,604\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:13:04,605\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-13-04\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 16\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9056587493368656\n",
      "  test_loss: tensor(813882.5000)\n",
      "  time_since_restore: 390.76667404174805\n",
      "  time_this_iter_s: 27.17414116859436\n",
      "  time_total_s: 390.76667404174805\n",
      "  timestamp: 1613772784\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.907644971223039\n",
      "  train_loss: 102484.9296875\n",
      "  training_iteration: 16\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:13:31,544\tWARNING util.py:132 -- The `process_trial` operation took 26.938361167907715 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         390.767</td><td style=\"text-align: right;\">    16</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:13:31,549\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-13-31\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 17\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9091803783347803\n",
      "  test_loss: tensor(790441.2500)\n",
      "  time_since_restore: 417.710746049881\n",
      "  time_this_iter_s: 26.944072008132935\n",
      "  time_total_s: 417.710746049881\n",
      "  timestamp: 1613772811\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9107596265913588\n",
      "  train_loss: 100374.453125\n",
      "  training_iteration: 17\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:13:58,257\tWARNING util.py:132 -- The `process_trial` operation took 26.707414865493774 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         417.711</td><td style=\"text-align: right;\">    17</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:13:58,263\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.6 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-13-58\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 18\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9130957115640338\n",
      "  test_loss: tensor(767893.2500)\n",
      "  time_since_restore: 444.424516916275\n",
      "  time_this_iter_s: 26.713770866394043\n",
      "  time_total_s: 444.424516916275\n",
      "  timestamp: 1613772838\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9220754825926821\n",
      "  train_loss: 88119.0703125\n",
      "  training_iteration: 18\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:14:25,125\tWARNING util.py:132 -- The `process_trial` operation took 26.861846923828125 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         444.425</td><td style=\"text-align: right;\">    18</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:14:25,128\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.6 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:14:25,129\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-14-25\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 19\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.916461035322316\n",
      "  test_loss: tensor(743082.3750)\n",
      "  time_since_restore: 471.29204177856445\n",
      "  time_this_iter_s: 26.86752486228943\n",
      "  time_total_s: 471.29204177856445\n",
      "  timestamp: 1613772865\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9177105550047956\n",
      "  train_loss: 92863.015625\n",
      "  training_iteration: 19\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:14:50,659\tWARNING util.py:132 -- The `process_trial` operation took 25.529081106185913 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         471.292</td><td style=\"text-align: right;\">    19</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:14:50,663\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-14-50\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 20\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9204290330993107\n",
      "  test_loss: tensor(720372.3125)\n",
      "  time_since_restore: 496.82564401626587\n",
      "  time_this_iter_s: 25.533602237701416\n",
      "  time_total_s: 496.82564401626587\n",
      "  timestamp: 1613772890\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9213710605677533\n",
      "  train_loss: 91818.3359375\n",
      "  training_iteration: 20\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:15:17,206\tWARNING util.py:132 -- The `process_trial` operation took 26.542216777801514 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         496.826</td><td style=\"text-align: right;\">    20</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:15:17,209\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-15-17\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 21\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9224465320342912\n",
      "  test_loss: tensor(706076.7500)\n",
      "  time_since_restore: 523.3726289272308\n",
      "  time_this_iter_s: 26.546984910964966\n",
      "  time_total_s: 523.3726289272308\n",
      "  timestamp: 1613772917\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9211312973718748\n",
      "  train_loss: 92875.09375\n",
      "  training_iteration: 21\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:15:43,121\tWARNING util.py:132 -- The `process_trial` operation took 25.911617040634155 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         523.373</td><td style=\"text-align: right;\">    21</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:15:43,124\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:15:43,125\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-15-43\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 22\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9231960133679256\n",
      "  test_loss: tensor(696293.4375)\n",
      "  time_since_restore: 549.2879359722137\n",
      "  time_this_iter_s: 25.91530704498291\n",
      "  time_total_s: 549.2879359722137\n",
      "  timestamp: 1613772943\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9271861713478516\n",
      "  train_loss: 87525.46875\n",
      "  training_iteration: 22\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:16:09,027\tWARNING util.py:132 -- The `process_trial` operation took 25.901710271835327 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         549.288</td><td style=\"text-align: right;\">    22</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:16:09,030\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-16-09\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 23\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9282715242361536\n",
      "  test_loss: tensor(671140.2500)\n",
      "  time_since_restore: 575.1939549446106\n",
      "  time_this_iter_s: 25.90601897239685\n",
      "  time_total_s: 575.1939549446106\n",
      "  timestamp: 1613772969\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9275188216614118\n",
      "  train_loss: 86404.6953125\n",
      "  training_iteration: 23\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:16:35,046\tWARNING util.py:132 -- The `process_trial` operation took 26.014894008636475 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         575.194</td><td style=\"text-align: right;\">    23</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:16:35,050\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-16-35\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 24\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9306921642393706\n",
      "  test_loss: tensor(651564.7500)\n",
      "  time_since_restore: 601.2126319408417\n",
      "  time_this_iter_s: 26.01867699623108\n",
      "  time_total_s: 601.2126319408417\n",
      "  timestamp: 1613772995\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9308015191489736\n",
      "  train_loss: 82472.2421875\n",
      "  training_iteration: 24\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:16:41,323\tWARNING util.py:132 -- The `process_trial` operation took 6.271616220474243 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         601.213</td><td style=\"text-align: right;\">    24</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:16:41,325\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-16-41\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 25\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9301784718731583\n",
      "  test_loss: tensor(515522.3125)\n",
      "  time_since_restore: 607.4897220134735\n",
      "  time_this_iter_s: 6.277090072631836\n",
      "  time_total_s: 607.4897220134735\n",
      "  timestamp: 1613773001\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.92818947318401\n",
      "  train_loss: 83885.7109375\n",
      "  training_iteration: 25\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:17:07,500\tWARNING util.py:132 -- The `process_trial` operation took 26.174540758132935 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">          607.49</td><td style=\"text-align: right;\">    25</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:17:07,503\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:17:07,504\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-17-07\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 26\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9306683037677341\n",
      "  test_loss: tensor(644962.3750)\n",
      "  time_since_restore: 633.6671841144562\n",
      "  time_this_iter_s: 26.177462100982666\n",
      "  time_total_s: 633.6671841144562\n",
      "  timestamp: 1613773027\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9312966802359272\n",
      "  train_loss: 83719.71875\n",
      "  training_iteration: 26\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:17:34,564\tWARNING util.py:132 -- The `process_trial` operation took 27.059285163879395 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         633.667</td><td style=\"text-align: right;\">    26</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:17:34,568\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-17-34\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 27\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.932763453728541\n",
      "  test_loss: tensor(635009.4375)\n",
      "  time_since_restore: 660.7307729721069\n",
      "  time_this_iter_s: 27.063588857650757\n",
      "  time_total_s: 660.7307729721069\n",
      "  timestamp: 1613773054\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9397461138776075\n",
      "  train_loss: 72404.515625\n",
      "  training_iteration: 27\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:17:59,719\tWARNING util.py:132 -- The `process_trial` operation took 25.150454998016357 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         660.731</td><td style=\"text-align: right;\">    27</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:17:59,722\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-17-59\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 28\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9366453875771802\n",
      "  test_loss: tensor(485050.4375)\n",
      "  time_since_restore: 685.8856978416443\n",
      "  time_this_iter_s: 25.154924869537354\n",
      "  time_total_s: 685.8856978416443\n",
      "  timestamp: 1613773079\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9376750266632914\n",
      "  train_loss: 75779.109375\n",
      "  training_iteration: 28\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:18:26,374\tWARNING util.py:132 -- The `process_trial` operation took 26.651323795318604 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         685.886</td><td style=\"text-align: right;\">    28</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:18:26,377\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:18:26,378\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-18-26\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 29\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9390927148055781\n",
      "  test_loss: tensor(594968.3750)\n",
      "  time_since_restore: 712.5408821105957\n",
      "  time_this_iter_s: 26.655184268951416\n",
      "  time_total_s: 712.5408821105957\n",
      "  timestamp: 1613773106\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9428070638513023\n",
      "  train_loss: 73036.625\n",
      "  training_iteration: 29\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:18:53,568\tWARNING util.py:132 -- The `process_trial` operation took 27.18974804878235 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         712.541</td><td style=\"text-align: right;\">    29</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:18:53,572\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-18-53\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 30\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9407713302438244\n",
      "  test_loss: tensor(577831.)\n",
      "  time_since_restore: 739.7349269390106\n",
      "  time_this_iter_s: 27.194044828414917\n",
      "  time_total_s: 739.7349269390106\n",
      "  timestamp: 1613773133\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9415831142243505\n",
      "  train_loss: 72947.0859375\n",
      "  training_iteration: 30\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:19:20,594\tWARNING util.py:132 -- The `process_trial` operation took 27.0219829082489 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         739.735</td><td style=\"text-align: right;\">    30</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:19:20,599\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-19-20\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 31\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9407386984625026\n",
      "  test_loss: tensor(583919.8750)\n",
      "  time_since_restore: 766.761125087738\n",
      "  time_this_iter_s: 27.026198148727417\n",
      "  time_total_s: 766.761125087738\n",
      "  timestamp: 1613773160\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9397328783217826\n",
      "  train_loss: 74209.7265625\n",
      "  training_iteration: 31\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:19:47,227\tWARNING util.py:132 -- The `process_trial` operation took 26.62798500061035 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         766.761</td><td style=\"text-align: right;\">    31</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:19:47,231\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:19:47,232\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-19-47\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 32\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9441956594580917\n",
      "  test_loss: tensor(552883.8125)\n",
      "  time_since_restore: 793.3944931030273\n",
      "  time_this_iter_s: 26.633368015289307\n",
      "  time_total_s: 793.3944931030273\n",
      "  timestamp: 1613773187\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9455388603803117\n",
      "  train_loss: 70101.34375\n",
      "  training_iteration: 32\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:20:14,173\tWARNING util.py:132 -- The `process_trial` operation took 26.94069504737854 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         793.394</td><td style=\"text-align: right;\">    32</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:20:14,177\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-20-14\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 33\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9444184446354907\n",
      "  test_loss: tensor(549763.7500)\n",
      "  time_since_restore: 820.3398840427399\n",
      "  time_this_iter_s: 26.945390939712524\n",
      "  time_total_s: 820.3398840427399\n",
      "  timestamp: 1613773214\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9443329775017695\n",
      "  train_loss: 71844.828125\n",
      "  training_iteration: 33\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:20:40,579\tWARNING util.py:132 -- The `process_trial` operation took 26.401386976242065 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">          820.34</td><td style=\"text-align: right;\">    33</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:20:40,584\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-20-40\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 34\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9466998980402525\n",
      "  test_loss: tensor(532682.3750)\n",
      "  time_since_restore: 846.7463600635529\n",
      "  time_this_iter_s: 26.40647602081299\n",
      "  time_total_s: 846.7463600635529\n",
      "  timestamp: 1613773240\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9488471058247882\n",
      "  train_loss: 65403.9765625\n",
      "  training_iteration: 34\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:21:07,246\tWARNING util.py:132 -- The `process_trial` operation took 26.661365032196045 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         846.746</td><td style=\"text-align: right;\">    34</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:21:07,249\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:21:07,250\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-21-07\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 35\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9482322051851428\n",
      "  test_loss: tensor(519794.5625)\n",
      "  time_since_restore: 873.4131009578705\n",
      "  time_this_iter_s: 26.666740894317627\n",
      "  time_total_s: 873.4131009578705\n",
      "  timestamp: 1613773267\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9467532943731872\n",
      "  train_loss: 67006.1328125\n",
      "  training_iteration: 35\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:21:34,358\tWARNING util.py:132 -- The `process_trial` operation took 27.10780692100525 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         873.413</td><td style=\"text-align: right;\">    35</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:21:34,362\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-21-34\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 36\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9472522336834355\n",
      "  test_loss: tensor(533990.3750)\n",
      "  time_since_restore: 900.5254189968109\n",
      "  time_this_iter_s: 27.11231803894043\n",
      "  time_total_s: 900.5254189968109\n",
      "  timestamp: 1613773294\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.949101618034974\n",
      "  train_loss: 66379.9375\n",
      "  training_iteration: 36\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:21:41,389\tWARNING util.py:132 -- The `process_trial` operation took 7.026477813720703 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         900.525</td><td style=\"text-align: right;\">    36</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:21:41,391\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-21-41\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 37\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9479407827561654\n",
      "  test_loss: tensor(520571.3125)\n",
      "  time_since_restore: 907.5556221008301\n",
      "  time_this_iter_s: 7.030203104019165\n",
      "  time_total_s: 907.5556221008301\n",
      "  timestamp: 1613773301\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9429170420996267\n",
      "  train_loss: 70476.515625\n",
      "  training_iteration: 37\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:22:07,795\tWARNING util.py:132 -- The `process_trial` operation took 26.403545141220093 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         907.556</td><td style=\"text-align: right;\">    37</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:22:07,798\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:22:07,799\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-22-07\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 38\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9504634819650737\n",
      "  test_loss: tensor(504755.1562)\n",
      "  time_since_restore: 933.9620850086212\n",
      "  time_this_iter_s: 26.406462907791138\n",
      "  time_total_s: 933.9620850086212\n",
      "  timestamp: 1613773327\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9529429093163261\n",
      "  train_loss: 63825.5234375\n",
      "  training_iteration: 38\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:22:34,652\tWARNING util.py:132 -- The `process_trial` operation took 26.85254693031311 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         933.962</td><td style=\"text-align: right;\">    38</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:22:34,655\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-22-34\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 39\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.951659924110231\n",
      "  test_loss: tensor(499293.0625)\n",
      "  time_since_restore: 960.819000005722\n",
      "  time_this_iter_s: 26.85691499710083\n",
      "  time_total_s: 960.819000005722\n",
      "  timestamp: 1613773354\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9564293015782908\n",
      "  train_loss: 58863.32421875\n",
      "  training_iteration: 39\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:23:01,693\tWARNING util.py:132 -- The `process_trial` operation took 27.03686785697937 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         960.819</td><td style=\"text-align: right;\">    39</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:23:01,696\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-23-01\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 40\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9514711811198625\n",
      "  test_loss: tensor(506753.8750)\n",
      "  time_since_restore: 987.859699010849\n",
      "  time_this_iter_s: 27.040699005126953\n",
      "  time_total_s: 987.859699010849\n",
      "  timestamp: 1613773381\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9523842392568213\n",
      "  train_loss: 62983.515625\n",
      "  training_iteration: 40\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:23:28,085\tWARNING util.py:132 -- The `process_trial` operation took 26.3889319896698 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">          987.86</td><td style=\"text-align: right;\">    40</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:23:28,088\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:23:28,089\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-23-28\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 41\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9531969773341012\n",
      "  test_loss: tensor(486085.4375)\n",
      "  time_since_restore: 1014.252329826355\n",
      "  time_this_iter_s: 26.39263081550598\n",
      "  time_total_s: 1014.252329826355\n",
      "  timestamp: 1613773408\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.955224302419718\n",
      "  train_loss: 60163.31640625\n",
      "  training_iteration: 41\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:23:55,252\tWARNING util.py:132 -- The `process_trial` operation took 27.16292691230774 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1014.25</td><td style=\"text-align: right;\">    41</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:23:55,257\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.6 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-23-55\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 42\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9524496866614558\n",
      "  test_loss: tensor(495758.9375)\n",
      "  time_since_restore: 1041.4194478988647\n",
      "  time_this_iter_s: 27.167118072509766\n",
      "  time_total_s: 1041.4194478988647\n",
      "  timestamp: 1613773435\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9522548444275173\n",
      "  train_loss: 63513.5078125\n",
      "  training_iteration: 42\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:24:22,432\tWARNING util.py:132 -- The `process_trial` operation took 27.174622058868408 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.12 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1041.42</td><td style=\"text-align: right;\">    42</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:24:22,435\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.6 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-24-22\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 43\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9540679737919414\n",
      "  test_loss: tensor(477418.9062)\n",
      "  time_since_restore: 1068.5991368293762\n",
      "  time_this_iter_s: 27.179688930511475\n",
      "  time_total_s: 1068.5991368293762\n",
      "  timestamp: 1613773462\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9569194160827678\n",
      "  train_loss: 59270.3984375\n",
      "  training_iteration: 43\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:24:49,582\tWARNING util.py:132 -- The `process_trial` operation took 27.14577603340149 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">          1068.6</td><td style=\"text-align: right;\">    43</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:24:49,585\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.6 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:24:49,585\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-24-49\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 44\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9550019277770851\n",
      "  test_loss: tensor(470492.4688)\n",
      "  time_since_restore: 1095.7486708164215\n",
      "  time_this_iter_s: 27.149533987045288\n",
      "  time_total_s: 1095.7486708164215\n",
      "  timestamp: 1613773489\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9578602347637453\n",
      "  train_loss: 58955.4453125\n",
      "  training_iteration: 44\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:25:16,815\tWARNING util.py:132 -- The `process_trial` operation took 27.22864270210266 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1095.75</td><td style=\"text-align: right;\">    44</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:25:16,819\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-25-16\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 45\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9566637010108551\n",
      "  test_loss: tensor(461814.6875)\n",
      "  time_since_restore: 1122.9816930294037\n",
      "  time_this_iter_s: 27.233022212982178\n",
      "  time_total_s: 1122.9816930294037\n",
      "  timestamp: 1613773516\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9567855101737092\n",
      "  train_loss: 58816.95703125\n",
      "  training_iteration: 45\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:25:43,726\tWARNING util.py:132 -- The `process_trial` operation took 26.906537294387817 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1122.98</td><td style=\"text-align: right;\">    45</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:25:43,730\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-25-43\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 46\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9567271505907952\n",
      "  test_loss: tensor(461424.0938)\n",
      "  time_since_restore: 1149.8932478427887\n",
      "  time_this_iter_s: 26.91155481338501\n",
      "  time_total_s: 1149.8932478427887\n",
      "  timestamp: 1613773543\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9578685381832598\n",
      "  train_loss: 57016.62109375\n",
      "  training_iteration: 46\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:26:12,210\tWARNING util.py:132 -- The `process_trial` operation took 28.479971885681152 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1149.89</td><td style=\"text-align: right;\">    46</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:26:12,214\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.6 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:26:12,215\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-26-12\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 47\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9571590195653994\n",
      "  test_loss: tensor(455625.1250)\n",
      "  time_since_restore: 1178.3772311210632\n",
      "  time_this_iter_s: 28.483983278274536\n",
      "  time_total_s: 1178.3772311210632\n",
      "  timestamp: 1613773572\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9595179812651509\n",
      "  train_loss: 56566.58203125\n",
      "  training_iteration: 47\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:26:39,922\tWARNING util.py:132 -- The `process_trial` operation took 27.70668315887451 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1178.38</td><td style=\"text-align: right;\">    47</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:26:39,926\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-26-39\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 48\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9582383880881573\n",
      "  test_loss: tensor(449219.2812)\n",
      "  time_since_restore: 1206.0887191295624\n",
      "  time_this_iter_s: 27.711488008499146\n",
      "  time_total_s: 1206.0887191295624\n",
      "  timestamp: 1613773599\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9609754451565642\n",
      "  train_loss: 54007.87109375\n",
      "  training_iteration: 48\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:26:47,185\tWARNING util.py:132 -- The `process_trial` operation took 7.259428024291992 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1206.09</td><td style=\"text-align: right;\">    48</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:26:47,188\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-26-47\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 49\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9591644114143951\n",
      "  test_loss: tensor(440776.4375)\n",
      "  time_since_restore: 1213.3525149822235\n",
      "  time_this_iter_s: 7.263795852661133\n",
      "  time_total_s: 1213.3525149822235\n",
      "  timestamp: 1613773607\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9624031717513567\n",
      "  train_loss: 53817.33203125\n",
      "  training_iteration: 49\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:27:14,262\tWARNING util.py:132 -- The `process_trial` operation took 27.07345414161682 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1213.35</td><td style=\"text-align: right;\">    49</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:27:14,266\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:27:14,267\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-27-14\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 50\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9593595753645846\n",
      "  test_loss: tensor(438242.6875)\n",
      "  time_since_restore: 1240.4288909435272\n",
      "  time_this_iter_s: 27.07637596130371\n",
      "  time_total_s: 1240.4288909435272\n",
      "  timestamp: 1613773634\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9614116638991029\n",
      "  train_loss: 53286.1796875\n",
      "  training_iteration: 50\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:27:42,513\tWARNING util.py:132 -- The `process_trial` operation took 28.245797872543335 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1240.43</td><td style=\"text-align: right;\">    50</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:27:42,517\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-27-42\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 51\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9608244468458201\n",
      "  test_loss: tensor(435093.3750)\n",
      "  time_since_restore: 1268.6801719665527\n",
      "  time_this_iter_s: 28.251281023025513\n",
      "  time_total_s: 1268.6801719665527\n",
      "  timestamp: 1613773662\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9598844677587504\n",
      "  train_loss: 54223.8515625\n",
      "  training_iteration: 51\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:28:10,310\tWARNING util.py:132 -- The `process_trial` operation took 27.792205810546875 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1268.68</td><td style=\"text-align: right;\">    51</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:28:10,314\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-28-10\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 52\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9620949832509466\n",
      "  test_loss: tensor(419266.3750)\n",
      "  time_since_restore: 1296.4773530960083\n",
      "  time_this_iter_s: 27.797181129455566\n",
      "  time_total_s: 1296.4773530960083\n",
      "  timestamp: 1613773690\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9610984831223903\n",
      "  train_loss: 53200.57421875\n",
      "  training_iteration: 52\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:28:38,459\tWARNING util.py:132 -- The `process_trial` operation took 28.144218683242798 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1296.48</td><td style=\"text-align: right;\">    52</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:28:38,465\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:28:38,465\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-28-38\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 53\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9619105861733778\n",
      "  test_loss: tensor(417997.5625)\n",
      "  time_since_restore: 1324.6261019706726\n",
      "  time_this_iter_s: 28.148748874664307\n",
      "  time_total_s: 1324.6261019706726\n",
      "  timestamp: 1613773718\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9643136607244632\n",
      "  train_loss: 50475.42578125\n",
      "  training_iteration: 53\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:29:05,063\tWARNING util.py:132 -- The `process_trial` operation took 26.597748041152954 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1324.63</td><td style=\"text-align: right;\">    53</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:29:05,072\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-29-05\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 54\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9623915217029124\n",
      "  test_loss: tensor(410239.3750)\n",
      "  time_since_restore: 1351.2305250167847\n",
      "  time_this_iter_s: 26.60442304611206\n",
      "  time_total_s: 1351.2305250167847\n",
      "  timestamp: 1613773745\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9644014899031161\n",
      "  train_loss: 52502.8515625\n",
      "  training_iteration: 54\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:29:32,375\tWARNING util.py:132 -- The `process_trial` operation took 27.303039073944092 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1351.23</td><td style=\"text-align: right;\">    54</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:29:32,379\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-29-32\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 55\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9631904253897743\n",
      "  test_loss: tensor(410782.0625)\n",
      "  time_since_restore: 1378.542503118515\n",
      "  time_this_iter_s: 27.311978101730347\n",
      "  time_total_s: 1378.542503118515\n",
      "  timestamp: 1613773772\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.962576562490172\n",
      "  train_loss: 54674.33984375\n",
      "  training_iteration: 55\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:29:59,237\tWARNING util.py:132 -- The `process_trial` operation took 26.85804319381714 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1378.54</td><td style=\"text-align: right;\">    55</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:29:59,240\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:29:59,241\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-29-59\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 56\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9626091857359291\n",
      "  test_loss: tensor(414434.6875)\n",
      "  time_since_restore: 1405.40438914299\n",
      "  time_this_iter_s: 26.861886024475098\n",
      "  time_total_s: 1405.40438914299\n",
      "  timestamp: 1613773799\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.965374387383215\n",
      "  train_loss: 51303.2734375\n",
      "  training_iteration: 56\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:30:26,199\tWARNING util.py:132 -- The `process_trial` operation took 26.95754599571228 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">          1405.4</td><td style=\"text-align: right;\">    56</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:30:26,202\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-30-26\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 57\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9635517083630595\n",
      "  test_loss: tensor(404545.2500)\n",
      "  time_since_restore: 1432.366178035736\n",
      "  time_this_iter_s: 26.96178889274597\n",
      "  time_total_s: 1432.366178035736\n",
      "  timestamp: 1613773826\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9665505025421977\n",
      "  train_loss: 50272.81640625\n",
      "  training_iteration: 57\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:30:53,397\tWARNING util.py:132 -- The `process_trial` operation took 27.193592071533203 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1432.37</td><td style=\"text-align: right;\">    57</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:30:53,400\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-30-53\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 58\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9645120432846951\n",
      "  test_loss: tensor(396596.4688)\n",
      "  time_since_restore: 1459.5636320114136\n",
      "  time_this_iter_s: 27.19745397567749\n",
      "  time_total_s: 1459.5636320114136\n",
      "  timestamp: 1613773853\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9635940220089857\n",
      "  train_loss: 51374.2109375\n",
      "  training_iteration: 58\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:31:21,049\tWARNING util.py:132 -- The `process_trial` operation took 27.648491144180298 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1459.56</td><td style=\"text-align: right;\">    58</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:31:21,053\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:31:21,053\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-31-21\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 59\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9652232950428153\n",
      "  test_loss: tensor(394866.2188)\n",
      "  time_since_restore: 1487.2159359455109\n",
      "  time_this_iter_s: 27.65230393409729\n",
      "  time_total_s: 1487.2159359455109\n",
      "  timestamp: 1613773881\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9645109217416217\n",
      "  train_loss: 52672.40234375\n",
      "  training_iteration: 59\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:31:49,012\tWARNING util.py:132 -- The `process_trial` operation took 27.958171129226685 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1487.22</td><td style=\"text-align: right;\">    59</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:31:49,016\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-31-49\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 60\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9660793534415101\n",
      "  test_loss: tensor(387639.5938)\n",
      "  time_since_restore: 1515.1786489486694\n",
      "  time_this_iter_s: 27.96271300315857\n",
      "  time_total_s: 1515.1786489486694\n",
      "  timestamp: 1613773909\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9672959595832685\n",
      "  train_loss: 47952.0546875\n",
      "  training_iteration: 60\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:31:55,977\tWARNING util.py:132 -- The `process_trial` operation took 6.960377216339111 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1515.18</td><td style=\"text-align: right;\">    60</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:31:55,979\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-31-55\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 61\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9664095046296337\n",
      "  test_loss: tensor(378336.6875)\n",
      "  time_since_restore: 1522.1437921524048\n",
      "  time_this_iter_s: 6.965143203735352\n",
      "  time_total_s: 1522.1437921524048\n",
      "  timestamp: 1613773915\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9678719404431227\n",
      "  train_loss: 49036.1640625\n",
      "  training_iteration: 61\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:32:22,416\tWARNING util.py:132 -- The `process_trial` operation took 26.436625957489014 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1522.14</td><td style=\"text-align: right;\">    61</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:32:22,420\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:32:22,421\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-32-22\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 62\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9657160664918437\n",
      "  test_loss: tensor(387027.)\n",
      "  time_since_restore: 1548.5833010673523\n",
      "  time_this_iter_s: 26.43950891494751\n",
      "  time_total_s: 1548.5833010673523\n",
      "  timestamp: 1613773942\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9692162620578112\n",
      "  train_loss: 46215.64453125\n",
      "  training_iteration: 62\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:32:49,569\tWARNING util.py:132 -- The `process_trial` operation took 27.147874116897583 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1548.58</td><td style=\"text-align: right;\">    62</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:32:49,572\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-32-49\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 63\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9659802555882046\n",
      "  test_loss: tensor(384748.0312)\n",
      "  time_since_restore: 1575.7361660003662\n",
      "  time_this_iter_s: 27.152864933013916\n",
      "  time_total_s: 1575.7361660003662\n",
      "  timestamp: 1613773969\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9688557792802716\n",
      "  train_loss: 46579.32421875\n",
      "  training_iteration: 63\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:33:16,882\tWARNING util.py:132 -- The `process_trial` operation took 27.309043884277344 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1575.74</td><td style=\"text-align: right;\">    63</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:33:16,885\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-33-16\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 64\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9666311701987651\n",
      "  test_loss: tensor(381022.6562)\n",
      "  time_since_restore: 1603.0490989685059\n",
      "  time_this_iter_s: 27.31293296813965\n",
      "  time_total_s: 1603.0490989685059\n",
      "  timestamp: 1613773996\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.968746811578767\n",
      "  train_loss: 46633.28515625\n",
      "  training_iteration: 64\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:33:43,938\tWARNING util.py:132 -- The `process_trial` operation took 27.051659107208252 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1603.05</td><td style=\"text-align: right;\">    64</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:33:43,942\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:33:43,943\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-33-43\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 65\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9682602162555828\n",
      "  test_loss: tensor(291976.0938)\n",
      "  time_since_restore: 1630.104789018631\n",
      "  time_this_iter_s: 27.055690050125122\n",
      "  time_total_s: 1630.104789018631\n",
      "  timestamp: 1613774023\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.969033821217595\n",
      "  train_loss: 46564.1796875\n",
      "  training_iteration: 65\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:34:10,638\tWARNING util.py:132 -- The `process_trial` operation took 26.694314002990723 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">          1630.1</td><td style=\"text-align: right;\">    65</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:34:10,642\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-34-10\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 66\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9677740720389081\n",
      "  test_loss: tensor(374694.7812)\n",
      "  time_since_restore: 1656.8048858642578\n",
      "  time_this_iter_s: 26.70009684562683\n",
      "  time_total_s: 1656.8048858642578\n",
      "  timestamp: 1613774050\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9686891515831071\n",
      "  train_loss: 45634.0625\n",
      "  training_iteration: 66\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:34:38,768\tWARNING util.py:132 -- The `process_trial` operation took 28.125291109085083 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">          1656.8</td><td style=\"text-align: right;\">    66</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:34:38,773\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-34-38\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 67\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9677908300560814\n",
      "  test_loss: tensor(373727.7500)\n",
      "  time_since_restore: 1684.9350399971008\n",
      "  time_this_iter_s: 28.130154132843018\n",
      "  time_total_s: 1684.9350399971008\n",
      "  timestamp: 1613774078\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9696801408273497\n",
      "  train_loss: 45393.12890625\n",
      "  training_iteration: 67\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:35:07,848\tWARNING util.py:132 -- The `process_trial` operation took 29.074071884155273 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1684.94</td><td style=\"text-align: right;\">    67</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:35:07,851\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:35:07,851\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-35-07\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 68\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9696643212427127\n",
      "  test_loss: tensor(358808.8750)\n",
      "  time_since_restore: 1714.014554977417\n",
      "  time_this_iter_s: 29.079514980316162\n",
      "  time_total_s: 1714.014554977417\n",
      "  timestamp: 1613774107\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9713388616035158\n",
      "  train_loss: 43630.125\n",
      "  training_iteration: 68\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:35:37,291\tWARNING util.py:132 -- The `process_trial` operation took 29.439133882522583 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1714.01</td><td style=\"text-align: right;\">    68</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:35:37,295\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-35-37\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 69\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9694201910731436\n",
      "  test_loss: tensor(362684.3438)\n",
      "  time_since_restore: 1743.4581360816956\n",
      "  time_this_iter_s: 29.443581104278564\n",
      "  time_total_s: 1743.4581360816956\n",
      "  timestamp: 1613774137\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9699420396295347\n",
      "  train_loss: 45933.00390625\n",
      "  training_iteration: 69\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:36:05,173\tWARNING util.py:132 -- The `process_trial` operation took 27.878138780593872 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1743.46</td><td style=\"text-align: right;\">    69</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:36:05,177\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-36-05\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 70\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.970997541282415\n",
      "  test_loss: tensor(350267.0625)\n",
      "  time_since_restore: 1771.3403780460358\n",
      "  time_this_iter_s: 27.88224196434021\n",
      "  time_total_s: 1771.3403780460358\n",
      "  timestamp: 1613774165\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9725060946205986\n",
      "  train_loss: 42863.0625\n",
      "  training_iteration: 70\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:36:34,421\tWARNING util.py:132 -- The `process_trial` operation took 29.24332904815674 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1771.34</td><td style=\"text-align: right;\">    70</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:36:34,425\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:36:34,425\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-36-34\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 71\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9695903964577438\n",
      "  test_loss: tensor(354556.8438)\n",
      "  time_since_restore: 1800.5881760120392\n",
      "  time_this_iter_s: 29.247797966003418\n",
      "  time_total_s: 1800.5881760120392\n",
      "  timestamp: 1613774194\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9693669598169942\n",
      "  train_loss: 45460.88671875\n",
      "  training_iteration: 71\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:37:04,350\tWARNING util.py:132 -- The `process_trial` operation took 29.924193143844604 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1800.59</td><td style=\"text-align: right;\">    71</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:37:04,353\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-37-04\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 72\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9701650541713511\n",
      "  test_loss: tensor(353081.8125)\n",
      "  time_since_restore: 1830.5171160697937\n",
      "  time_this_iter_s: 29.928940057754517\n",
      "  time_total_s: 1830.5171160697937\n",
      "  timestamp: 1613774224\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9712251775050433\n",
      "  train_loss: 43711.33203125\n",
      "  training_iteration: 72\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:37:11,625\tWARNING util.py:132 -- The `process_trial` operation took 7.2711780071258545 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1830.52</td><td style=\"text-align: right;\">    72</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:37:11,628\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-37-11\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 73\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9704656791602749\n",
      "  test_loss: tensor(354333.0938)\n",
      "  time_since_restore: 1837.7924230098724\n",
      "  time_this_iter_s: 7.275306940078735\n",
      "  time_total_s: 1837.7924230098724\n",
      "  timestamp: 1613774231\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9711465129461733\n",
      "  train_loss: 45345.578125\n",
      "  training_iteration: 73\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:37:39,833\tWARNING util.py:132 -- The `process_trial` operation took 28.204375982284546 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1837.79</td><td style=\"text-align: right;\">    73</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:37:39,836\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:37:39,836\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-37-39\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 74\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9711080931884641\n",
      "  test_loss: tensor(343732.8125)\n",
      "  time_since_restore: 1865.999634027481\n",
      "  time_this_iter_s: 28.207211017608643\n",
      "  time_total_s: 1865.999634027481\n",
      "  timestamp: 1613774259\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9717085989149639\n",
      "  train_loss: 44296.10546875\n",
      "  training_iteration: 74\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:38:07,392\tWARNING util.py:132 -- The `process_trial` operation took 27.555517196655273 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">            1866</td><td style=\"text-align: right;\">    74</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:38:07,396\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-38-07\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 75\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9722464112410263\n",
      "  test_loss: tensor(338976.5938)\n",
      "  time_since_restore: 1893.5593740940094\n",
      "  time_this_iter_s: 27.55974006652832\n",
      "  time_total_s: 1893.5593740940094\n",
      "  timestamp: 1613774287\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.972073452223131\n",
      "  train_loss: 42162.03515625\n",
      "  training_iteration: 75\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:38:35,124\tWARNING util.py:132 -- The `process_trial` operation took 27.727933883666992 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1893.56</td><td style=\"text-align: right;\">    75</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:38:35,127\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-38-35\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 76\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9721738644755019\n",
      "  test_loss: tensor(334415.1562)\n",
      "  time_since_restore: 1921.2911479473114\n",
      "  time_this_iter_s: 27.731773853302002\n",
      "  time_total_s: 1921.2911479473114\n",
      "  timestamp: 1613774315\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9745725103492036\n",
      "  train_loss: 40025.23828125\n",
      "  training_iteration: 76\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:39:03,968\tWARNING util.py:132 -- The `process_trial` operation took 28.840343236923218 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1921.29</td><td style=\"text-align: right;\">    76</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:39:03,972\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:39:03,972\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-39-03\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 77\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.97178283911131\n",
      "  test_loss: tensor(339040.9375)\n",
      "  time_since_restore: 1950.1354279518127\n",
      "  time_this_iter_s: 28.844280004501343\n",
      "  time_total_s: 1950.1354279518127\n",
      "  timestamp: 1613774343\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9741215909423125\n",
      "  train_loss: 41402.0234375\n",
      "  training_iteration: 77\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:39:33,173\tWARNING util.py:132 -- The `process_trial` operation took 29.20044708251953 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 17.7/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1950.14</td><td style=\"text-align: right;\">    77</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:39:33,177\tINFO resource_spec.py:212 -- Starting Ray with 9.57 GiB memory available for workers and up to 4.8 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-39-33\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 78\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9727307010117388\n",
      "  test_loss: tensor(334109.7188)\n",
      "  time_since_restore: 1979.340031862259\n",
      "  time_this_iter_s: 29.204603910446167\n",
      "  time_total_s: 1979.340031862259\n",
      "  timestamp: 1613774373\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9758728761247932\n",
      "  train_loss: 39830.28125\n",
      "  training_iteration: 78\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:40:01,922\tWARNING util.py:132 -- The `process_trial` operation took 28.744344234466553 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 17.5/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.57 GiB heap, 0.0/3.27 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         1979.34</td><td style=\"text-align: right;\">    78</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:40:01,925\tINFO resource_spec.py:212 -- Starting Ray with 9.67 GiB memory available for workers and up to 4.84 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-40-01\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 79\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9718822350146298\n",
      "  test_loss: tensor(338042.1875)\n",
      "  time_since_restore: 2008.088840007782\n",
      "  time_this_iter_s: 28.74880814552307\n",
      "  time_total_s: 2008.088840007782\n",
      "  timestamp: 1613774401\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9735902499843974\n",
      "  train_loss: 41258.9921875\n",
      "  training_iteration: 79\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:40:30,129\tWARNING util.py:132 -- The `process_trial` operation took 28.20371913909912 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 17.6/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.67 GiB heap, 0.0/3.32 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2008.09</td><td style=\"text-align: right;\">    79</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:40:30,133\tINFO resource_spec.py:212 -- Starting Ray with 9.62 GiB memory available for workers and up to 4.83 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:40:30,133\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-40-30\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 80\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9720345112908165\n",
      "  test_loss: tensor(334964.4375)\n",
      "  time_since_restore: 2036.2963180541992\n",
      "  time_this_iter_s: 28.207478046417236\n",
      "  time_total_s: 2036.2963180541992\n",
      "  timestamp: 1613774430\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9739250669235197\n",
      "  train_loss: 42481.98046875\n",
      "  training_iteration: 80\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:41:00,116\tWARNING util.py:132 -- The `process_trial` operation took 29.982717275619507 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 17.9/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.62 GiB heap, 0.0/3.32 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">          2036.3</td><td style=\"text-align: right;\">    80</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:41:00,120\tINFO resource_spec.py:212 -- Starting Ray with 9.42 GiB memory available for workers and up to 4.72 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-41-00\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 81\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9725219711775206\n",
      "  test_loss: tensor(336902.3125)\n",
      "  time_since_restore: 2066.2835149765015\n",
      "  time_this_iter_s: 29.987196922302246\n",
      "  time_total_s: 2066.2835149765015\n",
      "  timestamp: 1613774460\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9734832870695834\n",
      "  train_loss: 40538.1484375\n",
      "  training_iteration: 81\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:41:29,380\tWARNING util.py:132 -- The `process_trial` operation took 29.259429216384888 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 17.9/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.42 GiB heap, 0.0/3.22 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2066.28</td><td style=\"text-align: right;\">    81</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:41:29,383\tINFO resource_spec.py:212 -- Starting Ray with 9.42 GiB memory available for workers and up to 4.72 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-41-29\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 82\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9730816496373235\n",
      "  test_loss: tensor(330367.2500)\n",
      "  time_since_restore: 2095.547231912613\n",
      "  time_this_iter_s: 29.26371693611145\n",
      "  time_total_s: 2095.547231912613\n",
      "  timestamp: 1613774489\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9720191572005112\n",
      "  train_loss: 44398.40234375\n",
      "  training_iteration: 82\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:41:58,563\tWARNING util.py:132 -- The `process_trial` operation took 29.178751945495605 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.0/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.42 GiB heap, 0.0/3.22 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2095.55</td><td style=\"text-align: right;\">    82</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:41:58,568\tINFO resource_spec.py:212 -- Starting Ray with 9.38 GiB memory available for workers and up to 4.69 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:41:58,568\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-41-58\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 83\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9738376094675316\n",
      "  test_loss: tensor(323014.3125)\n",
      "  time_since_restore: 2124.729864835739\n",
      "  time_this_iter_s: 29.18263292312622\n",
      "  time_total_s: 2124.729864835739\n",
      "  timestamp: 1613774518\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9770033902417045\n",
      "  train_loss: 37534.28515625\n",
      "  training_iteration: 83\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:42:27,695\tWARNING util.py:132 -- The `process_trial` operation took 29.12662386894226 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.0/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.38 GiB heap, 0.0/3.22 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2124.73</td><td style=\"text-align: right;\">    83</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:42:27,699\tINFO resource_spec.py:212 -- Starting Ray with 9.38 GiB memory available for workers and up to 4.7 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-42-27\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 84\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9735632298796947\n",
      "  test_loss: tensor(320620.7812)\n",
      "  time_since_restore: 2153.8622708320618\n",
      "  time_this_iter_s: 29.132405996322632\n",
      "  time_total_s: 2153.8622708320618\n",
      "  timestamp: 1613774547\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9756360372056271\n",
      "  train_loss: 39938.2265625\n",
      "  training_iteration: 84\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:42:35,149\tWARNING util.py:132 -- The `process_trial` operation took 7.449320077896118 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.38 GiB heap, 0.0/3.22 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2153.86</td><td style=\"text-align: right;\">    84</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:42:35,151\tINFO resource_spec.py:212 -- Starting Ray with 9.33 GiB memory available for workers and up to 4.68 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-42-35\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 85\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9726169616065724\n",
      "  test_loss: tensor(336297.0312)\n",
      "  time_since_restore: 2161.315953016281\n",
      "  time_this_iter_s: 7.45368218421936\n",
      "  time_total_s: 2161.315953016281\n",
      "  timestamp: 1613774555\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9772349243678415\n",
      "  train_loss: 37626.12890625\n",
      "  training_iteration: 85\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:43:04,516\tWARNING util.py:132 -- The `process_trial` operation took 29.364525079727173 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.33 GiB heap, 0.0/3.22 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2161.32</td><td style=\"text-align: right;\">    85</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:43:04,519\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.66 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:43:04,520\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-43-04\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 86\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9743846978499978\n",
      "  test_loss: tensor(319843.6562)\n",
      "  time_since_restore: 2190.6833069324493\n",
      "  time_this_iter_s: 29.367353916168213\n",
      "  time_total_s: 2190.6833069324493\n",
      "  timestamp: 1613774584\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9756376001249222\n",
      "  train_loss: 39689.9296875\n",
      "  training_iteration: 86\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:43:33,668\tWARNING util.py:132 -- The `process_trial` operation took 29.1472806930542 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2190.68</td><td style=\"text-align: right;\">    86</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:43:33,671\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-43-33\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 87\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.97520753322884\n",
      "  test_loss: tensor(314257.0625)\n",
      "  time_since_restore: 2219.8348479270935\n",
      "  time_this_iter_s: 29.151540994644165\n",
      "  time_total_s: 2219.8348479270935\n",
      "  timestamp: 1613774613\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.976782181317428\n",
      "  train_loss: 38366.984375\n",
      "  training_iteration: 87\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:44:02,541\tWARNING util.py:132 -- The `process_trial` operation took 28.86939311027527 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2219.83</td><td style=\"text-align: right;\">    87</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:44:02,544\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-44-02\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 88\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.974731075122028\n",
      "  test_loss: tensor(318572.5625)\n",
      "  time_since_restore: 2248.7081351280212\n",
      "  time_this_iter_s: 28.873287200927734\n",
      "  time_total_s: 2248.7081351280212\n",
      "  timestamp: 1613774642\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.975593983797911\n",
      "  train_loss: 38734.5078125\n",
      "  training_iteration: 88\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:44:31,570\tWARNING util.py:132 -- The `process_trial` operation took 29.025174140930176 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2248.71</td><td style=\"text-align: right;\">    88</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:44:31,573\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:44:31,574\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-44-31\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 89\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9758543837783311\n",
      "  test_loss: tensor(306027.7500)\n",
      "  time_since_restore: 2277.7370228767395\n",
      "  time_this_iter_s: 29.02888774871826\n",
      "  time_total_s: 2277.7370228767395\n",
      "  timestamp: 1613774671\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9748372170295629\n",
      "  train_loss: 40613.86328125\n",
      "  training_iteration: 89\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:45:00,084\tWARNING util.py:132 -- The `process_trial` operation took 28.509416818618774 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2277.74</td><td style=\"text-align: right;\">    89</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:45:00,089\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-45-00\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 90\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9751267841214458\n",
      "  test_loss: tensor(247105.7969)\n",
      "  time_since_restore: 2306.2507240772247\n",
      "  time_this_iter_s: 28.51370120048523\n",
      "  time_total_s: 2306.2507240772247\n",
      "  timestamp: 1613774700\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9769122777455934\n",
      "  train_loss: 38990.33203125\n",
      "  training_iteration: 90\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:45:28,066\tWARNING util.py:132 -- The `process_trial` operation took 27.976482152938843 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2306.25</td><td style=\"text-align: right;\">    90</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:45:28,069\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-45-28\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 91\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9753907443448149\n",
      "  test_loss: tensor(311921.4688)\n",
      "  time_since_restore: 2334.2333059310913\n",
      "  time_this_iter_s: 27.982581853866577\n",
      "  time_total_s: 2334.2333059310913\n",
      "  timestamp: 1613774728\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9780650251410816\n",
      "  train_loss: 36905.5859375\n",
      "  training_iteration: 91\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:45:56,641\tWARNING util.py:132 -- The `process_trial` operation took 28.57077717781067 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2334.23</td><td style=\"text-align: right;\">    91</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:45:56,644\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:45:56,644\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-45-56\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 92\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9755853245527756\n",
      "  test_loss: tensor(308786.0625)\n",
      "  time_since_restore: 2362.8078219890594\n",
      "  time_this_iter_s: 28.57451605796814\n",
      "  time_total_s: 2362.8078219890594\n",
      "  timestamp: 1613774756\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.977420189446571\n",
      "  train_loss: 38049.4453125\n",
      "  training_iteration: 92\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:46:25,778\tWARNING util.py:132 -- The `process_trial` operation took 29.132838010787964 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2362.81</td><td style=\"text-align: right;\">    92</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:46:25,781\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.6 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-46-25\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 93\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9757719481377213\n",
      "  test_loss: tensor(307242.5625)\n",
      "  time_since_restore: 2391.9446849823\n",
      "  time_this_iter_s: 29.136862993240356\n",
      "  time_total_s: 2391.9446849823\n",
      "  timestamp: 1613774785\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9770361114375916\n",
      "  train_loss: 38375.921875\n",
      "  training_iteration: 93\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:46:55,169\tWARNING util.py:132 -- The `process_trial` operation took 29.387691020965576 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2391.94</td><td style=\"text-align: right;\">    93</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:46:55,173\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-46-55\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 94\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.975282803069807\n",
      "  test_loss: tensor(312394.9062)\n",
      "  time_since_restore: 2421.3362448215485\n",
      "  time_this_iter_s: 29.391559839248657\n",
      "  time_total_s: 2421.3362448215485\n",
      "  timestamp: 1613774815\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9783999940944582\n",
      "  train_loss: 37165.6484375\n",
      "  training_iteration: 94\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:47:24,468\tWARNING util.py:132 -- The `process_trial` operation took 29.294437885284424 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2421.34</td><td style=\"text-align: right;\">    94</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:47:24,471\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:47:24,472\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-47-24\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 95\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9758893552391984\n",
      "  test_loss: tensor(307563.5625)\n",
      "  time_since_restore: 2450.6351778507233\n",
      "  time_this_iter_s: 29.298933029174805\n",
      "  time_total_s: 2450.6351778507233\n",
      "  timestamp: 1613774844\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9763854041171776\n",
      "  train_loss: 38583.15625\n",
      "  training_iteration: 95\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:47:52,599\tWARNING util.py:132 -- The `process_trial` operation took 28.126245260238647 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2450.64</td><td style=\"text-align: right;\">    95</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:47:52,602\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-47-52\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 96\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9756013143836905\n",
      "  test_loss: tensor(303027.2812)\n",
      "  time_since_restore: 2478.7657010555267\n",
      "  time_this_iter_s: 28.130523204803467\n",
      "  time_total_s: 2478.7657010555267\n",
      "  timestamp: 1613774872\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.976159172049799\n",
      "  train_loss: 39369.2734375\n",
      "  training_iteration: 96\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:47:59,606\tWARNING util.py:132 -- The `process_trial` operation took 7.0038840770721436 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2478.77</td><td style=\"text-align: right;\">    96</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:47:59,609\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-47-59\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 97\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9766798488626459\n",
      "  test_loss: tensor(300799.2188)\n",
      "  time_since_restore: 2485.7733709812164\n",
      "  time_this_iter_s: 7.007669925689697\n",
      "  time_total_s: 2485.7733709812164\n",
      "  timestamp: 1613774879\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9793642470252876\n",
      "  train_loss: 36222.9375\n",
      "  training_iteration: 97\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:48:27,878\tWARNING util.py:132 -- The `process_trial` operation took 28.26834988594055 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2485.77</td><td style=\"text-align: right;\">    97</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:48:27,881\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:48:27,881\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-48-27\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 98\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9747428040487123\n",
      "  test_loss: tensor(316248.3750)\n",
      "  time_since_restore: 2514.0446441173553\n",
      "  time_this_iter_s: 28.271273136138916\n",
      "  time_total_s: 2514.0446441173553\n",
      "  timestamp: 1613774907\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.978917999281567\n",
      "  train_loss: 35310.7578125\n",
      "  training_iteration: 98\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:48:56,235\tWARNING util.py:132 -- The `process_trial` operation took 28.353060960769653 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2514.04</td><td style=\"text-align: right;\">    98</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:48:56,238\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-48-56\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 99\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9759045454296975\n",
      "  test_loss: tensor(304771.8750)\n",
      "  time_since_restore: 2542.401787996292\n",
      "  time_this_iter_s: 28.357143878936768\n",
      "  time_total_s: 2542.401787996292\n",
      "  timestamp: 1613774936\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9792803549173739\n",
      "  train_loss: 35256.3046875\n",
      "  training_iteration: 99\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:49:24,605\tWARNING util.py:132 -- The `process_trial` operation took 28.366419076919556 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">          2542.4</td><td style=\"text-align: right;\">    99</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:49:24,608\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-49-24\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 100\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9772349680065846\n",
      "  test_loss: tensor(296859.3125)\n",
      "  time_since_restore: 2570.771826028824\n",
      "  time_this_iter_s: 28.37003803253174\n",
      "  time_total_s: 2570.771826028824\n",
      "  timestamp: 1613774964\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9770040718722283\n",
      "  train_loss: 38269.4765625\n",
      "  training_iteration: 100\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:49:54,389\tWARNING util.py:132 -- The `process_trial` operation took 29.780386924743652 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2570.77</td><td style=\"text-align: right;\">   100</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:49:54,392\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:49:54,393\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-49-54\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 101\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9769457752287181\n",
      "  test_loss: tensor(296493.5000)\n",
      "  time_since_restore: 2600.555998802185\n",
      "  time_this_iter_s: 29.784172773361206\n",
      "  time_total_s: 2600.555998802185\n",
      "  timestamp: 1613774994\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.977970942381725\n",
      "  train_loss: 36969.36328125\n",
      "  training_iteration: 101\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:50:23,154\tWARNING util.py:132 -- The `process_trial` operation took 28.760212898254395 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2600.56</td><td style=\"text-align: right;\">   101</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:50:23,157\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-50-23\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 102\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9782670836359657\n",
      "  test_loss: tensor(287258.2812)\n",
      "  time_since_restore: 2629.3206329345703\n",
      "  time_this_iter_s: 28.764634132385254\n",
      "  time_total_s: 2629.3206329345703\n",
      "  timestamp: 1613775023\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.980325761905639\n",
      "  train_loss: 34510.73046875\n",
      "  training_iteration: 102\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:50:52,221\tWARNING util.py:132 -- The `process_trial` operation took 29.06404972076416 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2629.32</td><td style=\"text-align: right;\">   102</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:50:52,225\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-50-52\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 103\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9773555510038517\n",
      "  test_loss: tensor(291233.7500)\n",
      "  time_since_restore: 2658.38845205307\n",
      "  time_this_iter_s: 29.067819118499756\n",
      "  time_total_s: 2658.38845205307\n",
      "  timestamp: 1613775052\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9795518037381096\n",
      "  train_loss: 35265.9921875\n",
      "  training_iteration: 103\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:51:21,845\tWARNING util.py:132 -- The `process_trial` operation took 29.61961603164673 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2658.39</td><td style=\"text-align: right;\">   103</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:51:21,848\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.6 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:51:21,849\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-51-21\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 104\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9779684109409617\n",
      "  test_loss: tensor(291474.8438)\n",
      "  time_since_restore: 2688.011859178543\n",
      "  time_this_iter_s: 29.623407125473022\n",
      "  time_total_s: 2688.011859178543\n",
      "  timestamp: 1613775081\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9803976043278714\n",
      "  train_loss: 33893.56640625\n",
      "  training_iteration: 104\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:51:51,860\tWARNING util.py:132 -- The `process_trial` operation took 30.010967016220093 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2688.01</td><td style=\"text-align: right;\">   104</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:51:51,863\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-51-51\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 105\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9786206459717052\n",
      "  test_loss: tensor(280966.4062)\n",
      "  time_since_restore: 2718.02716088295\n",
      "  time_this_iter_s: 30.01530170440674\n",
      "  time_total_s: 2718.02716088295\n",
      "  timestamp: 1613775111\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.980082579278676\n",
      "  train_loss: 35108.4453125\n",
      "  training_iteration: 105\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:52:21,411\tWARNING util.py:132 -- The `process_trial` operation took 29.547311067581177 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2718.03</td><td style=\"text-align: right;\">   105</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:52:21,415\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-52-21\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 106\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9786273912330455\n",
      "  test_loss: tensor(283266.1875)\n",
      "  time_since_restore: 2747.578006029129\n",
      "  time_this_iter_s: 29.5508451461792\n",
      "  time_total_s: 2747.578006029129\n",
      "  timestamp: 1613775141\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9795414641213713\n",
      "  train_loss: 36562.97265625\n",
      "  training_iteration: 106\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:52:51,390\tWARNING util.py:132 -- The `process_trial` operation took 29.973792791366577 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2747.58</td><td style=\"text-align: right;\">   106</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:52:51,393\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.63 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:52:51,394\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-52-51\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 107\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.978485803116012\n",
      "  test_loss: tensor(283544.5625)\n",
      "  time_since_restore: 2777.5567309856415\n",
      "  time_this_iter_s: 29.97872495651245\n",
      "  time_total_s: 2777.5567309856415\n",
      "  timestamp: 1613775171\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9813777952236269\n",
      "  train_loss: 34059.6015625\n",
      "  training_iteration: 107\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:53:21,392\tWARNING util.py:132 -- The `process_trial` operation took 29.99754309654236 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2777.56</td><td style=\"text-align: right;\">   107</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:53:21,395\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.6 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-53-21\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 108\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9787927128623908\n",
      "  test_loss: tensor(279874.1250)\n",
      "  time_since_restore: 2807.558610200882\n",
      "  time_this_iter_s: 30.00187921524048\n",
      "  time_total_s: 2807.558610200882\n",
      "  timestamp: 1613775201\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9786342428498264\n",
      "  train_loss: 35730.9453125\n",
      "  training_iteration: 108\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:53:28,353\tWARNING util.py:132 -- The `process_trial` operation took 6.9572718143463135 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2807.56</td><td style=\"text-align: right;\">   108</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:53:28,355\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-53-28\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 109\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9779370697495424\n",
      "  test_loss: tensor(286738.9688)\n",
      "  time_since_restore: 2814.519689798355\n",
      "  time_this_iter_s: 6.9610795974731445\n",
      "  time_total_s: 2814.519689798355\n",
      "  timestamp: 1613775208\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9783764617602326\n",
      "  train_loss: 35557.8203125\n",
      "  training_iteration: 109\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:53:57,791\tWARNING util.py:132 -- The `process_trial` operation took 29.435518980026245 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2814.52</td><td style=\"text-align: right;\">   109</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:53:57,794\tINFO resource_spec.py:212 -- Starting Ray with 9.28 GiB memory available for workers and up to 4.65 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:53:57,795\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-53-57\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 110\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.977895942503861\n",
      "  test_loss: tensor(286879.1250)\n",
      "  time_since_restore: 2843.958065032959\n",
      "  time_this_iter_s: 29.438375234603882\n",
      "  time_total_s: 2843.958065032959\n",
      "  timestamp: 1613775237\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9812978494378541\n",
      "  train_loss: 33201.23828125\n",
      "  training_iteration: 110\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:54:27,894\tWARNING util.py:132 -- The `process_trial` operation took 30.09807014465332 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.28 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2843.96</td><td style=\"text-align: right;\">   110</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:54:27,897\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-54-27\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 111\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9781356878779799\n",
      "  test_loss: tensor(283756.3750)\n",
      "  time_since_restore: 2874.0605080127716\n",
      "  time_this_iter_s: 30.102442979812622\n",
      "  time_total_s: 2874.0605080127716\n",
      "  timestamp: 1613775267\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9793472975310858\n",
      "  train_loss: 35834.9765625\n",
      "  training_iteration: 111\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:54:57,614\tWARNING util.py:132 -- The `process_trial` operation took 29.71698522567749 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2874.06</td><td style=\"text-align: right;\">   111</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:54:57,618\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-54-57\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 112\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9792124382531143\n",
      "  test_loss: tensor(275182.0938)\n",
      "  time_since_restore: 2903.7813081741333\n",
      "  time_this_iter_s: 29.720800161361694\n",
      "  time_total_s: 2903.7813081741333\n",
      "  timestamp: 1613775297\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9811119688162989\n",
      "  train_loss: 33319.375\n",
      "  training_iteration: 112\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:55:26,797\tWARNING util.py:132 -- The `process_trial` operation took 29.17911195755005 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2903.78</td><td style=\"text-align: right;\">   112</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:55:26,801\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.62 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:55:26,802\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-55-26\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 113\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9789321137223603\n",
      "  test_loss: tensor(278806.)\n",
      "  time_since_restore: 2932.964292049408\n",
      "  time_this_iter_s: 29.182983875274658\n",
      "  time_total_s: 2932.964292049408\n",
      "  timestamp: 1613775326\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9802225689420974\n",
      "  train_loss: 34822.46484375\n",
      "  training_iteration: 113\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:55:56,452\tWARNING util.py:132 -- The `process_trial` operation took 29.649558067321777 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.23 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2932.96</td><td style=\"text-align: right;\">   113</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:55:56,455\tINFO resource_spec.py:212 -- Starting Ray with 9.33 GiB memory available for workers and up to 4.67 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-55-56\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 114\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9792168392399601\n",
      "  test_loss: tensor(279142.6250)\n",
      "  time_since_restore: 2962.618931055069\n",
      "  time_this_iter_s: 29.65463900566101\n",
      "  time_total_s: 2962.618931055069\n",
      "  timestamp: 1613775356\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9820910858806082\n",
      "  train_loss: 32465.552734375\n",
      "  training_iteration: 114\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:56:25,887\tWARNING util.py:132 -- The `process_trial` operation took 29.431190967559814 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.33 GiB heap, 0.0/3.22 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2962.62</td><td style=\"text-align: right;\">   114</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:56:25,890\tINFO resource_spec.py:212 -- Starting Ray with 9.33 GiB memory available for workers and up to 4.67 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-56-25\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 115\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9799491953134266\n",
      "  test_loss: tensor(274789.5000)\n",
      "  time_since_restore: 2992.053824901581\n",
      "  time_this_iter_s: 29.43489384651184\n",
      "  time_total_s: 2992.053824901581\n",
      "  timestamp: 1613775385\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9790595378294368\n",
      "  train_loss: 35172.7734375\n",
      "  training_iteration: 115\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:56:56,056\tWARNING util.py:132 -- The `process_trial` operation took 30.165223836898804 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.33 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         2992.05</td><td style=\"text-align: right;\">   115</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:56:56,061\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:56:56,061\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-56-56\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 116\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9796193210453685\n",
      "  test_loss: tensor(274020.2500)\n",
      "  time_since_restore: 3022.222778081894\n",
      "  time_this_iter_s: 30.16895318031311\n",
      "  time_total_s: 3022.222778081894\n",
      "  timestamp: 1613775416\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9784281596694002\n",
      "  train_loss: 36585.86328125\n",
      "  training_iteration: 116\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:57:25,904\tWARNING util.py:132 -- The `process_trial` operation took 29.84217095375061 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         3022.22</td><td style=\"text-align: right;\">   116</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:57:25,909\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-57-25\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 117\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.978895463744201\n",
      "  test_loss: tensor(278391.7188)\n",
      "  time_since_restore: 3052.0713019371033\n",
      "  time_this_iter_s: 29.84852385520935\n",
      "  time_total_s: 3052.0713019371033\n",
      "  timestamp: 1613775445\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9800268392756998\n",
      "  train_loss: 34223.34375\n",
      "  training_iteration: 117\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:57:56,599\tWARNING util.py:132 -- The `process_trial` operation took 30.68943428993225 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.2/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         3052.07</td><td style=\"text-align: right;\">   117</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:57:56,602\tINFO resource_spec.py:212 -- Starting Ray with 9.18 GiB memory available for workers and up to 4.61 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:57:56,603\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-57-56\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 118\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9800556199716741\n",
      "  test_loss: tensor(272616.4688)\n",
      "  time_since_restore: 3082.766247034073\n",
      "  time_this_iter_s: 30.694945096969604\n",
      "  time_total_s: 3082.766247034073\n",
      "  timestamp: 1613775476\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9800615644364669\n",
      "  train_loss: 34264.703125\n",
      "  training_iteration: 118\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:58:25,548\tWARNING util.py:132 -- The `process_trial` operation took 28.944200038909912 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.0/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.18 GiB heap, 0.0/3.17 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         3082.77</td><td style=\"text-align: right;\">   118</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:58:25,552\tINFO resource_spec.py:212 -- Starting Ray with 9.33 GiB memory available for workers and up to 4.67 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-58-25\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 119\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.979067754210745\n",
      "  test_loss: tensor(220735.6562)\n",
      "  time_since_restore: 3111.714798927307\n",
      "  time_this_iter_s: 28.948551893234253\n",
      "  time_total_s: 3111.714798927307\n",
      "  timestamp: 1613775505\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.979935652624038\n",
      "  train_loss: 34672.5390625\n",
      "  training_iteration: 119\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:58:55,301\tWARNING util.py:132 -- The `process_trial` operation took 29.74756669998169 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.1/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/9.33 GiB heap, 0.0/3.22 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>RUNNING </td><td>192.168.68.106:32472</td><td style=\"text-align: right;\">         3111.71</td><td style=\"text-align: right;\">   119</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:58:55,304\tINFO resource_spec.py:212 -- Starting Ray with 9.23 GiB memory available for workers and up to 4.64 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_ba455998:\n",
      "  date: 2021-02-19_17-58-55\n",
      "  done: false\n",
      "  experiment_id: 69b3fbd9f9144deca47ded7ddb48fff7\n",
      "  experiment_tag: '0'\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 120\n",
      "  node_ip: 192.168.68.106\n",
      "  pid: 32472\n",
      "  test_f1: 0.9810875743168316\n",
      "  test_loss: tensor(260888.8125)\n",
      "  time_since_restore: 3141.4677789211273\n",
      "  time_this_iter_s: 29.75297999382019\n",
      "  time_total_s: 3141.4677789211273\n",
      "  timestamp: 1613775535\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.9820663318475144\n",
      "  train_loss: 32768.3203125\n",
      "  training_iteration: 120\n",
      "  trial_id: ba455998\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:58:58,601\tWARNING util.py:132 -- The `process_trial` operation took 3.2964859008789062 seconds to complete, which may be a performance bottleneck.\n",
      "2021-02-19 17:58:58,602\tINFO resource_spec.py:212 -- Starting Ray with 16.02 GiB memory available for workers and up to 8.01 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2021-02-19 17:58:58,603\tWARNING ray_trial_executor.py:361 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n",
      "/usr/local/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 6.9/32.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/12 CPUs, 0/0 GPUs, 0.0/16.02 GiB heap, 0.0/5.52 GiB objects<br>Result logdir: /Users/natasha/Desktop/TUNE_RESULT_DIR/17_02_2021_40mods<br>Number of trials: 1 (1 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  iter</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_ba455998</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">         3141.47</td><td style=\"text-align: right;\">   120</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-19 17:58:58,617\tINFO tune.py:352 -- Returning an analysis object by default. You can call `analysis.trials` to retrieve a list of trials. This message will be removed in future versions of Tune.\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    trainable.train_AE, \n",
    "    name=\"17_02_2021_40mods\",\n",
    "    config=config_corruption,\n",
    "    verbose=2, \n",
    "    resources_per_trial={\n",
    "            \"cpu\": 10,\n",
    "            \"gpu\": 0\n",
    "    },\n",
    "    #num_samples=20,\n",
    "    num_samples=1,\n",
    "    queue_trials=True,\n",
    "    local_dir=\"/Users/natasha/Desktop/TUNE_RESULT_DIR\",\n",
    "    #local_dir=\"/home/ndudek/projects/def-dprecup/ndudek/hp_tuning_01-10-2020/TUNE_RESULT_DIR\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Best config is:\", analysis.get_best_config(metric=\"test_f1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis.get_best_config(metric=\"test_f1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single model: Define and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_layers = 3\n",
    "# weight_decay = 0.1\n",
    "# lr = 0.001\n",
    "# batch_size = 128\n",
    "# kfolds = 10\n",
    "# num_epochs = 10\n",
    "# replacement_threshold = 0.5\n",
    "\n",
    "# kld0, bce0, train_losses, test_losses, train_f1s, test_f1s, model = trainable.train_single_vae(nn_layers, weight_decay, lr, batch_size, kfolds, num_epochs, replacement_threshold, corrupted_train, corrupted_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version = \"0mod\"\n",
    "# torch.save(model.state_dict(), BASE_DIR+\"_\"+version+\"_model.pt\")\n",
    "\n",
    "# torch.save(train_losses, BASE_DIR+\"_\"+version+\"_train_losses.pt\")\n",
    "# torch.save(test_losses, BASE_DIR+\"_\"+version+\"_test_losses.pt\")\n",
    "# torch.save(bce0, BASE_DIR+\"_\"+version+\"_bce0.pt\")\n",
    "# torch.save(kld0, BASE_DIR+\"_\"+version+\"_kld0.pt\")\n",
    "# torch.save(train_f1s, BASE_DIR+\"_\"+version+\"_train_f1s.pt\")\n",
    "# torch.save(test_f1s, BASE_DIR+\"_\"+version+\"_test_f1s.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = True\n",
    "version = \"10mod\"\n",
    "if load_model:\n",
    "    from genome_embeddings import models\n",
    "    n_features = int(corrupted_train.shape[1]/2)\n",
    "    model = models.VariationalAutoEncoder(n_features, 3)\n",
    "    model.load_state_dict(torch.load(BASE_DIR+\"_\"+version+\"_model.pt\"))\n",
    "    train_losses = torch.load(BASE_DIR+\"_\"+version+\"_train_losses.pt\")\n",
    "    test_losses = torch.load(BASE_DIR+\"_\"+version+\"_test_losses.pt\")\n",
    "    train_f1s = torch.load(BASE_DIR+\"_\"+version+\"_train_f1s.pt\")\n",
    "    test_f1s = torch.load(BASE_DIR+\"_\"+version+\"_test_f1s.pt\")\n",
    "    bce0 = torch.load(BASE_DIR+\"_\"+version+\"_bce0.pt\")\n",
    "    kld0 = torch.load(BASE_DIR+\"_\"+version+\"_kld0.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-10 modules per input genome: 0.74\n",
    "# 1 module per input genome: 0.64\n",
    "# 10 modules per input genome: 0.81\n",
    "n_features = int(corrupted_test.shape[1]/2)\n",
    "corrupted = corrupted_test[:,:n_features]\n",
    "uncorrupted = corrupted_test[:,n_features:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = False\n",
    "\n",
    "model.eval()\n",
    "\n",
    "if new_preds:\n",
    "    with torch.no_grad():\n",
    "        pred = model.forward(corrupted)[0].detach()\n",
    "    binary_pred = evaluate.eval_binarize(pred, 0.5)\n",
    "    torch.save(pred, BASE_DIR+\"_preds.pt\")\n",
    "    torch.save(binary_pred, BASE_DIR+\"_binary_preds.pt\")\n",
    "else:\n",
    "    pred = torch.load(BASE_DIR+\"_preds.pt\")\n",
    "    binary_pred = torch.load(BASE_DIR+\"_binary_preds.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate test set F1 score (micro-average) and calculate TNs, FPs, FNs, TPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = sk.metrics.f1_score(uncorrupted, binary_pred, zero_division=0, average='micro')\n",
    "print(\"Test set F1 score\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1s, fig = evaluate.test_f1s(uncorrupted, binary_pred)\n",
    "plt.savefig(BASE_DIR+\"f1_dist.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns, fps, fns, tps, total = evaluate.glom_confusion(uncorrupted, binary_pred)\n",
    "print(round(sum(tns)/total*100,2), round(sum(fps)/total*100,2), round(sum(fns)/total*100,2), round(sum(tps)/total*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine at BCE vs KLD loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot BCE and KLD vs experience\n",
    "data_viz.kld_vs_bce(kld0,bce0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = data_viz.learning_curve(train_losses, test_losses, train_f1s, test_f1s)\n",
    "plt.savefig(BASE_DIR+\"learning_curves.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROC curve and generate AUC score (micro-average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = int(corrupted_test.shape[1]/2)\n",
    "true_genomes = corrupted_test[:,num_features:]\n",
    "fig = data_viz.my_roc_curve(true_genomes.numpy(), pred.numpy())\n",
    "fig.savefig(BASE_DIR+\"roc_fig.pdf\", dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the input genes present in the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6675 instance of inputs being 100% present in output\n",
      "This is out of 27900 instances or 23.92% of cases\n",
      "There are 23774 instance of inputs being >=90% present in output (85.21%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# relabel y axis by % rather than count\n",
    "fig, _ = evaluate.compare_in_n_out(binary_pred, corrupted)\n",
    "fig.savefig(BASE_DIR+\"input_vs_output.pdf\", bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the best and worst performing instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# babt = Brucella abortus\n",
    "idx_best = f1s.index(max(f1s))\n",
    "tla_best = c_test_genomes[idx_best]\n",
    "idx_best, tla_best, f1s[idx_best], tla_to_tnum[tla_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nmv = Nitrospira moscoviensis\n",
    "# seny = Pectobacteriaceae sodalis (Gammaprot), endosymbiont of Henestaris halophilus\n",
    "# bmx\n",
    "idx_worst = f1s.index(min(f1s))\n",
    "tla_worst = c_test_genomes[idx_worst]\n",
    "idx_worst, tla_worst, f1s[idx_worst], tla_to_tnum[tla_worst]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the best scoring instance, plot pixel diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = idx_best\n",
    "fig = data_viz.genome_heatmap2(corrupted_test, idx, model, f1s, tns, fps, fns, tps, binary_pred)\n",
    "fig.savefig(BASE_DIR+\"fig4.pdf\", bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num genes on in uncorrupted idx_best genome\", torch.sum(uncorrupted[idx_best,:]))\n",
    "print(\"Num genes off in uncorrupted idx_best genome\", n_features - torch.sum(uncorrupted[idx_best,:]))\n",
    "print(\"Num genes on in corrupted idx_best genome\", torch.sum(corrupted[idx_best,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = evaluate.snowplot(f1s, c_test_genomes, tns, fps, fns, tps, uncorrupted, corrupted, idx_best)\n",
    "fig.savefig(BASE_DIR+\"barh.pdf\", bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the worst scoring instance, plot pixel diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = idx_worst\n",
    "fig = data_viz.genome_heatmap2(corrupted_test, idx, model, f1s, tns, fps, fns, tps, binary_pred)\n",
    "fig.savefig(BASE_DIR+\"fig4.png\", bbox_inches='tight', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print median TNs, FPs, FNs, TPs\n",
    "np.median(tns), np.median(fps), np.median(fns), np.median(tps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the model perform on inputs originating from different phyla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dicts to map genome tla back to list of phylum, class, etc\n",
    "train_tax_dict, test_tax_dict = data_viz.tax_distribution(c_train_genomes, c_test_genomes, 'Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_per_phy = defaultdict(int)\n",
    "for tnum in test_genomes:\n",
    "    tla = tnum_to_tla[tnum]\n",
    "    phylum = test_tax_dict[tla][1]\n",
    "    if phylum == 'Proteobacteria':\n",
    "        phylum = test_tax_dict[tla][2]\n",
    "    count_per_phy[phylum] += 1\n",
    "count_per_phy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_phyla, test_phyla = evaluate.f1s_per_phylum(train_tax_dict, test_tax_dict, c_test_genomes, f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of phyla in train + test sets\n",
    "len(set(list(train_phyla.keys()) + list(test_phyla.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bars represent median absolute deviation\n",
    "fig_save_for_later = evaluate.plot_f1_per_phylum(test_phyla, (5,10))\n",
    "fig_save_for_later.savefig(BASE_DIR+\"f1_per_phylum.png\", dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are the results between phyla statistically significant?\n",
    "stats.kruskal(*test_phyla.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = evaluate.plot_count_vs_f1s(train_phyla, test_phyla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There appears to be an effect of number of training genomes / phylum on test set per phylum F1 score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times is each mod used in the various corrupted inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of times each mod occurs in the training set corrupted genomes\n",
    "train_out = evaluate.train_out(train_input_mods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = evaluate.plot_train_count_hist(train_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does genome size correlate with F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x-axis = # genes in input genome\n",
    "# y-axis = F1 score of reconstructed genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes_uncorrupted = torch.sum(uncorrupted, 1).numpy().tolist() # get sum of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(n_genes_uncorrupted, f1s, marker='.', s = 1)\n",
    "plt.xlabel(\"# genes in uncorrupted genome\")\n",
    "plt.ylabel(\"F1 score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_genes_corrupted = torch.sum(corrupted, 1).numpy().tolist() # get sum of each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(n_genes_corrupted, f1s, marker='.', s = 1)\n",
    "plt.xlabel(\"# genes in corrupted input\")\n",
    "plt.ylabel(\"F1 score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How much variance is there in the F1 score of genomes encoding certain modules?\n",
    "Do some modules / lifestyles get reconstructed better than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_to_mod, mod_to_proc = evaluate.map_proc_mod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, done = evaluate.plot_mod_count_vs_f1(test_input_mods, c_test_genomes, train_input_mods, f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = evaluate.plot_mod_vs_f1(test_input_mods, f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot whether number of modules in process correlates with F1 score\n",
    "# More interchangeable options = worse performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess_to_mod, mod_to_subproc = evaluate.map_subproc_mod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = evaluate.plot_metab_pathway_f1(subprocess_to_mod, test_input_mods, f1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze F1 scores of actual KOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS MUST BE USED IN MULTIPLE PLACES\n",
    "ko_f1s = []\n",
    "for i in range(uncorrupted.shape[1]): # for every column\n",
    "    f1 = sk.metrics.f1_score(uncorrupted[:,i], binary_pred[:,i], zero_division=0)\n",
    "    ko_f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = 0\n",
    "for i in ko_f1s:\n",
    "    if i == 0:\n",
    "        zeros += 1\n",
    "print(zeros, len(ko_f1s), zeros/len(ko_f1s)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the training set, how many KOs are always zero?\n",
    "zeros_train = train_data.sum(axis=0) > 0\n",
    "n_ones = np.sum(zeros_train)\n",
    "n_zeros_train = len(zeros_train) - n_ones\n",
    "print(\"There are\",n_zeros_train,\"genes that are always off in the training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.hist(ko_f1s, bins = 50)\n",
    "plt.xlabel(\"F1 score per gene\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene occurence in uncorrupted ds vs F1 score\n",
    "#ko_counts = torch.sum(uncorrupted, 0)\n",
    "# get gene occurence in uncorrupted training set\n",
    "tr_uncorrupted = corrupted_train[:,n_features:]\n",
    "ko_counts = torch.sum(tr_uncorrupted, 0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.scatter(ko_counts, ko_f1s, marker='.', s = 1)\n",
    "ax.set_xlim(0, tr_uncorrupted.shape[0])\n",
    "ax.set_ylim(0,1)\n",
    "plt.xlabel(\"gene count in uncorrupted train set\")\n",
    "plt.ylabel(\"per gene test F1 score\")\n",
    "plt.xticks(rotation=-70)\n",
    "print(\"max KO count:\",int(max(ko_counts)), \", total number of training genomes:\",tr_uncorrupted.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate figure for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15, 5))\n",
    "\n",
    "phylum_f1s = [np.median(test_phyla[i]) for i in test_phyla]\n",
    "phylum_count = [train_phyla[i] for i in test_phyla]\n",
    "ax1.scatter(phylum_count, phylum_f1s)\n",
    "ax1.set_xlabel(\"Number of genomes in train set\")\n",
    "ax1.set_ylabel(\"F1 score on test set\")\n",
    "ax1.set_xscale('log')\n",
    "\n",
    "tr_uncorrupted = corrupted_train[:,n_features:]\n",
    "ko_counts = torch.sum(tr_uncorrupted, 0)\n",
    "ax2.scatter(ko_counts, ko_f1s, marker='.', s = 1)\n",
    "ax2.set_xlim(0, tr_uncorrupted.shape[0])\n",
    "ax2.set_ylim(0,1)\n",
    "ax2.set_xlabel(\"Gene count in uncorrupted train set\")\n",
    "ax2.set_ylabel(\"Ger gene test F1 score\")\n",
    "\n",
    "n_genes_uncorrupted = torch.sum(uncorrupted, 1).numpy().tolist() # get sum of each row\n",
    "ax3.scatter(n_genes_uncorrupted, f1s, marker='.', s = 1)\n",
    "ax3.set_xlabel(\"# genes in original test genome\")\n",
    "ax3.set_ylabel(\"F1 score on test set\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(BASE_DIR+\"bio_insights_contd.pdf\", dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score on KOs + what metab pathway they are part of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = evaluate.plot_metab_pathway_f1_v2(process_to_mod, mod_to_ko_clean, all_kos, ko_f1s, (7,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# can also do horizontal boxplot with fig = evaluate.plot_metab_pathway_f1_v2\n",
    "fig, proc_to_ko_F1s = evaluate.plot_metab_pathway_f1_v2_horizontal(subprocess_to_mod, mod_to_ko_clean, all_kos, ko_f1s, (5,10))\n",
    "#fig.savefig(BASE_DIR+\"f1_per_proc.png\", dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kruskal(*proc_to_ko_F1s.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### How does the model do on different types of genes (kinases vs transferases, etc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = evaluate.bio_insights_fig(test_phyla, subprocess_to_mod, all_kos, ko_f1s, mod_to_ko_clean)\n",
    "fig.savefig(BASE_DIR+\"bio_insights_fig.pdf\", dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the count of each mod in training set (pre-corruption) correlate with median F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = evaluate.plot_mod_count_vs_f1_v2(test_input_mods, f1s, train_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitatively compare distance of real vs generated genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 100 genomes using random sets of 10 modules\n",
    "new_genomes = False\n",
    "\n",
    "if new_genomes:\n",
    "    from datetime import date\n",
    "    date = date.today()\n",
    "    generated, generated_inputs = evaluate.generate_genomes(100, all_kos, mod_to_ko_clean, 10, model)\n",
    "    torch.save(generated, BASE_DIR+\"generated_genomes_\"+str(date)+\".pt\")\n",
    "    torch.save(generated_inputs, BASE_DIR+\"generated_genome_inputs_\"+str(date)+\".pt\")\n",
    "else:\n",
    "#     generated = torch.load(BASE_DIR+\"generated_genomes_11_01_2020.pt\")\n",
    "#     generated_inputs = torch.load(BASE_DIR+\"generated_genome_inputs_11_01_2020.pt\")\n",
    "    generated = torch.load(BASE_DIR+\"generated_genomes_2021-02-01.pt\")\n",
    "    generated_inputs = torch.load(BASE_DIR+\"generated_genome_inputs_2021-02-01.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot PCA of Jaccard similarity between genomes, using Hamming distances as a metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx 292 Num genes in selected genome 2015\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = random.randint(279, 379) # assumes 279 test genomes + 100 generated genomes, 0-indexed\n",
    "#idx = 368 # pathogen\n",
    "#idx = 282 # heme biosyn\n",
    "idx = 292\n",
    "gen_idx = idx - test_data.shape[0] # generated genomes follow test set genomes in tensor\n",
    "print(\"idx\",str(idx),\"Num genes in selected genome\", int(torch.sum(generated[gen_idx])))\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "#fig = evaluate.plot_dist(generated_genomes, all_kos, mod_to_ko_clean, model, test_data)\n",
    "fig = evaluate.plot_dist(generated, all_kos, mod_to_ko_clean, model, test_data, idx)\n",
    "fig.savefig(BASE_DIR+\"pca_jaccard.pdf\", dpi=200, bbox_inches='tight');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_corrupted = np.zeros((len(generated_inputs), n_features))\n",
    "\n",
    "for i in range(len(generated_inputs)):\n",
    "    kos_in = generated_inputs[i][1] # get KOs used as inputs\n",
    "    ko_idx = [all_kos.index(i) for i in kos_in] # get col index of those KOs in the data tensor\n",
    "    gen_corrupted[i][ko_idx] = 1 # turn on genes at those indices\n",
    "\n",
    "gen_corrupted = torch.Tensor(gen_corrupted).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 instance of inputs being 100% present in output\n",
      "This is out of 100 instances or 100.0% of cases\n",
      "There are 100 instance of inputs being >=90% present in output (100.0%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, out = evaluate.compare_in_n_out(generated, gen_corrupted)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# generate protein output for a genome generated in set of 100 above\n",
    "#save_to = BASE_DIR+'prot_out_'+str(idx)+'.txt'\n",
    "#evaluate.generate_out2(generated, gen_idx, all_kos, BASE_DIR, save_to)\n",
    "print('Genome was generated using the following mods as input')\n",
    "generated_inputs[gen_idx][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(generated_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make list of KOs in generated genome\n",
    "gen_ko_idx = [int(i) for i in (generated[gen_idx] == 1).nonzero()]\n",
    "gen_kos = [all_kos[i] for i in gen_ko_idx]\n",
    "len(gen_kos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess ribosomal completeness\n",
    "pathways.confirm_ribosome(gen_kos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess rRNA gene completeness\n",
    "pathways.confirm_rrna(gen_kos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'K21254' in gen_kos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each mod number, get its name\n",
    "mod_to_name = pre_process.mod_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_completeness(genome_vector, mod_to_ko_clean, mod):\n",
    "    count = 0\n",
    "    for i in mod_to_ko_clean[mod]:\n",
    "        if i in genome_vector:\n",
    "            count += 1\n",
    "        else:\n",
    "            print(\"missing\", i)\n",
    "    print(count,\"/\",len(mod_to_ko_clean[mod]),\"genes in the mod are present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in generated_inputs[gen_idx][0]:\n",
    "    print(mod, mod_to_name[mod])\n",
    "    print(mod_to_ko_clean[mod])\n",
    "    mod_completeness(gen_kos, mod_to_ko_clean, mod)\n",
    "    print(\"--------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to = BASE_DIR+\"prot_out_\"+str(gen_idx)+\".txt\"\n",
    "\n",
    "with open(BASE_DIR+'seq_dict.pkl', 'rb') as handle:\n",
    "    seq_dict = pickle.load(handle)\n",
    "\n",
    "with open(save_to, 'w') as handle:\n",
    "    for prot in gen_kos:\n",
    "        handle.write(\">\"+prot+\"\\n\")\n",
    "        handle.write(seq_dict[prot]+\"\\n\")\n",
    "\n",
    "print(gen_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input to KEGG Mapper\n",
    "for i, ko in enumerate(gen_kos):\n",
    "    print(\"gene\"+str(i), ko)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of genes and modules per genome for real vs generated genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_mods(generated, all_kos, mod_to_ko_clean):\n",
    "    gen_kos = defaultdict(list)\n",
    "    for i, row in enumerate(generated):\n",
    "        for j in range(len(row)):\n",
    "            if row[j] == 1:\n",
    "                gen_kos[i].append(all_kos[j])\n",
    "\n",
    "    gen_mods = defaultdict(list)\n",
    "    for genome in gen_kos:\n",
    "        my_kos = gen_kos[genome]\n",
    "\n",
    "        for mod in mod_to_ko_clean:\n",
    "            complete = True\n",
    "            for ko in mod_to_ko_clean[mod]:\n",
    "                if ko not in my_kos: \n",
    "                    complete = False\n",
    "\n",
    "            if complete:\n",
    "                gen_mods[genome].append(mod)\n",
    "                \n",
    "    return gen_mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_freqs(mod_to_ko_clean, test_data, generated):\n",
    "\n",
    "    real_mod_freq = []\n",
    "    gen_mod_freq = []\n",
    "    for mod in mod_to_ko_clean:\n",
    "        real_count = 0\n",
    "        gen_count = 0\n",
    "        for genome in gen_mods:\n",
    "            if mod in gen_mods[genome]:\n",
    "                gen_count += 1\n",
    "            if mod in real_mods[genome]:\n",
    "                real_count += 1\n",
    "        real_mod_freq.append(real_count / len(test_data))\n",
    "        gen_mod_freq.append(gen_count / len(generated))\n",
    "\n",
    "    # sort in descending order of real genome mods\n",
    "    real_mod_freq, gen_mod_freq = zip(*sorted(zip(real_mod_freq, gen_mod_freq), reverse=True))\n",
    "\n",
    "    return real_mod_freq, gen_mod_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_mods = complete_mods(generated, all_kos, mod_to_ko_clean)\n",
    "real_mods = complete_mods(test_data, all_kos, mod_to_ko_clean)\n",
    "gen_mod_lens = [len(gen_mods[i]) for i in gen_mods]\n",
    "real_mod_lens = [len(real_mods[i]) for i in gen_mods]\n",
    "\n",
    "real_mod_freq, gen_mod_freq = mod_freqs(mod_to_ko_clean, test_data, generated)\n",
    "labels = [i for i in range(len(gen_mod_freq))]\n",
    "\n",
    "len_gen = []\n",
    "for genome in generated:\n",
    "    len_gen.append(torch.sum(genome))\n",
    "len_real = []\n",
    "for genome in test_data:\n",
    "    len_real.append(np.sum(genome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "#plt.yticks(fontsize=20) \n",
    "\n",
    "# Plot number of genes per genome\n",
    "ax1.hist(len_real, 50, color='g', alpha=0.5)\n",
    "ax1.hist(len_gen, 50, color='b', alpha=0.5)\n",
    "#ax1.legend(['Real', 'Generated'])\n",
    "ax1.set_xlabel(\"Number of genes\")\n",
    "ax1.set_ylabel(\"Genome count\")\n",
    "\n",
    "# Plot number of complete mods per genome\n",
    "ax2.hist(gen_mod_lens, 50, color='b', alpha=0.5)\n",
    "ax2.hist(real_mod_lens, 50, color='g', alpha=0.5)\n",
    "#ax2.legend(['Real', 'Generated'])\n",
    "ax2.set_xlabel(\"Number of complete modules\")\n",
    "ax2.set_ylabel(\"Genome count\")\n",
    "\n",
    "# Plot the fraction of genomes encoding each mod\n",
    "ax3.bar(labels, gen_mod_freq, color='b', alpha=0.5)\n",
    "ax3.bar(labels, real_mod_freq, color='g', alpha=0.5)\n",
    "ax3.legend(['Real', 'Generated'])\n",
    "ax3.set_xlabel(\"Module\")\n",
    "ax3.set_ylabel(\"Fraction of genomes \\n encoding module\")\n",
    "ax3.set_xlim(0,len(labels))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(BASE_DIR+\"count_dists.pdf\", dpi=200, bbox_inches='tight')\n",
    "fig.savefig(BASE_DIR+\"count_dists.png\", dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create files needed to infer and visualize a dendrogram based on gene prescence/abscence\n",
    "Will use phylip to infer a parsimony-based dendrogram (mix program)\n",
    "\n",
    "Will use iTOL for visualization (display, add colour strips, remove taxon labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barc_vec = evaluate.arch_root(all_kos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat tensor for input to phylip\n",
    "df = evaluate.df_for_phylip(generated, test_data, test_genomes, all_kos)\n",
    "df = df.append(pd.DataFrame({col: [val] for col, val in zip(df.columns, barc_vec)}, ['outgroup_T04065']))\n",
    "phylum_dict = evaluate.write_out_for_phylip(BASE_DIR, df, tnum_to_tla, test_tax_dict) # phylip_in.txt\n",
    "#df.to_csv(BASE_DIR+'generated_genomes.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "same = True\n",
    "for i in range(len(generated[13])):\n",
    "    if int(df.iloc[292][i]) != int(generated[13][i]):\n",
    "        same = False\n",
    "same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find \"phylip-3.695-vol\", double click \"mix\" program\n",
    "# Enter file name with path to dir ---> delete space at the end of the file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For parsimony dendrogram: generate real genomes' phylum-level colour strip file for iTOL \n",
    "phyla_colours = evaluate.get_phyla_colours()\n",
    "evaluate.colour_real_itol(BASE_DIR, phyla_colours, phylum_dict) # vae_dendro_colours_real.txt\n",
    "#colour = tuple(np.random.randint(256, size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For parsimony dendrogram: generate generated genomes' colour strip file for iTOL\n",
    "evaluate.colour_generated_itol(BASE_DIR, phylum_dict) # vae_dendro_colours_generated.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as sk\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 1: randomly turn on n_rand bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = False\n",
    "\n",
    "if new:\n",
    "    print(\"Generating new baseline 1\")\n",
    "    baseline1 = evaluate.baseline1(corrupted_train, org_to_mod_to_kos, org_to_kos, tla_to_tnum, c_train_genomes, corrupted_test)\n",
    "    torch.save(baseline1, BASE_DIR+\"baseline1.pt\")\n",
    "else:\n",
    "    print(\"Loading previously made baseline 1\")\n",
    "    baseline1 = torch.load(BASE_DIR+\"baseline1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = sk.metrics.f1_score(uncorrupted, baseline1, zero_division=0, average='micro')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tns, fps, fns, tps, total = evaluate.glom_confusion(uncorrupted, baseline1)\n",
    "print(round(sum(tns)/total*100,2), round(sum(fps)/total*100,2), round(sum(fns)/total*100,2), round(sum(tps)/total*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve, generate AUC score (micro-average)\n",
    "num_features = int(corrupted_test.shape[1]/2)\n",
    "fig = data_viz.my_roc_curve(uncorrupted.numpy(), baseline1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2: randomly turn on n_rand bits with the highest probability of being on across the entire training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = True\n",
    "\n",
    "if new:\n",
    "    print(\"Generating new baseline 2\")\n",
    "    baseline2 = evaluate.baseline2(corrupted_test, org_to_mod_to_kos, org_to_kos, tla_to_tnum, c_train_genomes, corrupted_test)\n",
    "    torch.save(baseline2, BASE_DIR+\"baseline2.pt\")\n",
    "else:\n",
    "    print(\"Loading previously made baseline 2\")\n",
    "    baseline2 = torch.load(BASE_DIR+\"baseline2.pt\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = sk.metrics.f1_score(uncorrupted, baseline2, zero_division=0, average='micro')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns, fps, fns, tps, total = evaluate.glom_confusion(uncorrupted, baseline2)\n",
    "print(round(sum(tns)/total*100,2), round(sum(fps)/total*100,2), round(sum(fns)/total*100,2), round(sum(tps)/total*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve, generate AUC score (micro-average)\n",
    "num_features = int(corrupted_test.shape[1]/2)\n",
    "fig = data_viz.my_roc_curve(uncorrupted.numpy(), baseline2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 3: Create predictions using an untrained version of the VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = True\n",
    "\n",
    "if new:\n",
    "    print(\"Generating new baseline 3\")\n",
    "    n_features = int(corrupted_test.shape[1]/2)\n",
    "    fake_model = models.VariationalAutoEncoder(n_features, 3)\n",
    "    fake_model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = fake_model.forward(corrupted_test[:,:n_features])[0].detach()\n",
    "    baseline3 = evaluate.eval_binarize(pred, 0.5)\n",
    "    torch.save(baseline3, BASE_DIR+\"baseline3.pt\")\n",
    "else:\n",
    "    print(\"Loading previously made baseline 3\")\n",
    "    baseline3 = torch.load(BASE_DIR+\"baseline3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = sk.metrics.f1_score(uncorrupted.long(), baseline3.long(), zero_division=0, average='micro')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns, fps, fns, tps, total = evaluate.glom_confusion(uncorrupted, baseline3)\n",
    "print(round(sum(tns)/total*100,2), round(sum(fps)/total*100,2), round(sum(fns)/total*100,2), round(sum(tps)/total*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve, generate AUC score (micro-average)\n",
    "num_features = int(corrupted_test.shape[1]/2)\n",
    "fig = data_viz.my_roc_curve(uncorrupted.numpy(), baseline3.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 4: Always predict the smallest genome in the training set (Hoaglandella endobia -- hed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = True\n",
    "\n",
    "if new:\n",
    "    print(\"Generating new baseline 4\")\n",
    "    baseline4 = evaluate.baseline4(corrupted_train, corrupted_test, tla_to_tnum, org_to_kos, c_train_genomes)\n",
    "    torch.save(baseline4, BASE_DIR+\"baseline4.pt\")\n",
    "else:\n",
    "    print(\"Loading previously made baseline 4\")\n",
    "    baseline4 = torch.load(BASE_DIR+\"baseline4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = sk.metrics.f1_score(uncorrupted, baseline4, zero_division=0, average='micro')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns, fps, fns, tps, total = evaluate.glom_confusion(uncorrupted, baseline4)\n",
    "print(round(sum(tns)/total*100,2), round(sum(fps)/total*100,2), round(sum(fns)/total*100,2), round(sum(tps)/total*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve, generate AUC score (micro-average)\n",
    "num_features = int(corrupted_test.shape[1]/2)\n",
    "fig = data_viz.my_roc_curve(uncorrupted.numpy(), baseline4.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 5: Always predict the largest genome in the training set (Paraburkholderia caribensis -- bcai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = True\n",
    "\n",
    "if new:\n",
    "    print(\"Generating new baseline 5\")\n",
    "    baseline5, largest_tla = evaluate.baseline5(corrupted_train, corrupted_test, tla_to_tnum, org_to_kos, c_train_genomes)\n",
    "    torch.save(baseline5, BASE_DIR+\"baseline5.pt\")\n",
    "else:\n",
    "    print(\"Loading previously made baseline 5\")\n",
    "    baseline5 = torch.load(BASE_DIR+\"baseline5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = sk.metrics.f1_score(uncorrupted, baseline5, zero_division=0, average='micro')\n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tns, fps, fns, tps, total = evaluate.glom_confusion(uncorrupted, baseline5)\n",
    "print(round(sum(tns)/total*100,2), round(sum(fps)/total*100,2), round(sum(fns)/total*100,2), round(sum(tps)/total*100,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve, generate AUC score (micro-average)\n",
    "num_features = int(corrupted_test.shape[1]/2)\n",
    "fig = data_viz.my_roc_curve(uncorrupted.numpy(), baseline5.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential model improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase dataset set (more corruptions per genome)\n",
    "# For genomes it does poorly on, make more copies\n",
    "# HP tuning\n",
    "# Remove genomes with <1000 KOs ---> get rid of endosymbionts --- will need to redo small genome baseline\n",
    "# Apply different amounts of KLD importance during training\n",
    "# Make 100% of input genes in output (currently ~20% have 100% in and out). Loss mod?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We performed a parameter sweep over warmups (κ) (0.01, 0.05, 0.1, and 1). \n",
    "# κ controls how much the KL divergence loss contributes to learning, \n",
    "# which effectively transitions a deterministic autoencoder to a VAE.28,29 \n",
    "# For instance, a κ = 0.1 would add 0.1 to a weight on the KL loss after each epoch. \n",
    "# After 10 epochs, the KL loss will have equal weight as the reconstruction loss. \n",
    "# We did not observe κ to influence model training (Figure 1B), so we kept κ = 1 for downstream analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model output to KAAS input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate NEW genome from 10 random modules\n",
    "\n",
    "######### ensure desired KOs are in output file --- did not happen when used above with tensor instead of df\n",
    "\n",
    "save_to = BASE_DIR+'prot_out_'+str(gen_idx)+'.txt'\n",
    "ko_new = evaluate.new_genome_random(mod_to_ko_clean, model, all_kos, save_to, BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
