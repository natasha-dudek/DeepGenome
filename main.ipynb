{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically upload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from genome_embeddings import data_viz\n",
    "from genome_embeddings import evaluate\n",
    "from genome_embeddings import models\n",
    "from genome_embeddings import train_test\n",
    "from genome_embeddings import util\n",
    "from genome_embeddings import trainable # import before ray (?)\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = Namespace(\n",
    "    DATA_FP = '/Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/data/', \n",
    "    SAVE_FP = '/Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/',\n",
    "    KEGG_FP = '/Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/kegg_dataset/',\n",
    "    data_source = 'kegg', #['get_homologues' | 'kegg']\n",
    "    n_test = 0.1, # train-test split, n * 100 = % of data that goes into test set (e.g.: 0.1 -> 10%)\n",
    "    num_epochs = 3, # IF CIRRICULUM, DO NOT SET < 3\n",
    "    batch_size = 128,\n",
    "    lr = 1e-3,\n",
    "    kfolds = 10, # number of folds for cross-validation\n",
    "    print_every = 50, # print loss every n batches during training (5)\n",
    "    replacement_threshold = 0.5, # probability over which binarizer converts to a 1\n",
    "    num_corruptions = 100, # number of corrupted versions of a genome to produce\n",
    "    corruption_fraction = 0.5, # fraction of genes to retain during corruption process\n",
    "    phy_mode = \"bacteria_only\", # training with only bacteria vs also euk/arch\n",
    "    cirriculum = False, # implement cirriculum learning based on gene count\n",
    "    rare_threshold = 10, # drop features that occur fewer than this times in training ds \n",
    "    weight_decay=0.1 # L2 regularization\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration + preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # First create genome representations (very slow)\n",
    "# # Each genome is a list of KO's and/or KEGG modules\n",
    "# if os.path.isfile(flags.DATA_FP+'genome_to_mod.csv'):\n",
    "#     print(\"Genome representations already exist\")\n",
    "# else:\n",
    "#     genome_rep.genome_kos(flags.KEGG_FP)\n",
    "#     print(\"Must generate genome representations from scratch. This will take several hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, cluster_names = util.load_data(flags.DATA_FP, flags.data_source)\n",
    "# genome_to_tax = util.genome_to_tax(df)\n",
    "# with open('cluster_names.txt', 'wb') as filehandle:\n",
    "#     pickle.dump(cluster_names, filehandle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.tax_distrib(df, genome_to_tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.module_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.genes_per_genome(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split train-test sets in a phylogenetically balanced manner \n",
    "# if os.path.isfile(flags.DATA_FP+'uncorrupted_train_balanced.csv'):\n",
    "#     print(\"Train-test split already exists, loading from file\")\n",
    "#     train_orig = pd.read_csv(flags.DATA_FP+\"uncorrupted_train_balanced.csv\", index_col=0)    \n",
    "#     test_orig = pd.read_csv(flags.DATA_FP+\"uncorrupted_test_balanced.csv\", index_col=0)    \n",
    "\n",
    "# else:\n",
    "#     # Create dict mapping each genome to a unique numerical ID\n",
    "#     genome_to_num ={}\n",
    "#     for i,genome in enumerate(df.index):\n",
    "#         genome_to_num[genome] = i\n",
    "\n",
    "#     num_to_genome = {v: k for k, v in genome_to_num.items()}\n",
    "        \n",
    "#     print(\"Generating train-test split\")\n",
    "#     train_orig, test_orig = util.balanced_split(df, flags.n_test, genome_to_tax, \n",
    "#                                                 num_to_genome, flags.DATA_FP)    \n",
    "#     train_orig.to_csv(flags.DATA_FP+'uncorrupted_train_balanced.csv')\n",
    "#     test_orig.to_csv(flags.DATA_FP+'uncorrupted_test_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.hist_prob_ko(train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if flags.phy_mode == \"bacteria_only\":\n",
    "#     train_genomes = train_orig.index.to_list()\n",
    "#     test_genomes = test_orig.index.to_list()\n",
    "    \n",
    "#     unf_train_data, train_tax_dict = util.bacteria_only(train_orig, train_genomes, genome_to_tax)\n",
    "#     unf_test_data, test_tax_dict = util.bacteria_only(test_orig, test_genomes, genome_to_tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove rare features from train + test datasets\n",
    "# # Rare = fewer than n occurences in training dataset\n",
    "# # Last argument specifies n, set to correspond to 1% of genomes (3432 genomes -> n = 34)\n",
    "# train_data, test_data, cluster_names = util.remove_rare(unf_train_data, unf_test_data, \n",
    "#                                                         cluster_names, unf_train_data.shape[0]*0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupted genomes already exist\n"
     ]
    }
   ],
   "source": [
    "# Produce corrupted genomes\n",
    "# Could eventually do re-sampling / extra-corrupting to have more examples of \"rare\" genome types\n",
    "#    e.g.: those from underrepresented groups M00003   \n",
    "\n",
    "if os.path.isfile(flags.DATA_FP+'corrupted_train_0607.pt'):\n",
    "    print(\"Corrupted genomes already exist\")\n",
    "    train_data = torch.load(flags.DATA_FP+\"corrupted_train_0607.pt\")\n",
    "    test_data = torch.load(flags.DATA_FP+\"corrupted_test_0607.pt\")\n",
    "    genome_idx_train = torch.load(flags.DATA_FP+\"genome_idx_train_0607.pt\")\n",
    "    genome_idx_test = torch.load(flags.DATA_FP+\"genome_idx_test_0607.pt\")\n",
    "else:\n",
    "    print(\"Generating corrupted dataset from scratch with\",flags.num_corruptions,\"corrupted versions of each genome\")\n",
    "    train_data, genome_idx_train = util.corrupt(train_data, flags.num_corruptions, flags.corruption_fraction, \n",
    "                                                cluster_names, \"train\", flags.DATA_FP)\n",
    "\n",
    "    test_data, genome_idx_test = util.corrupt(test_data, flags.num_corruptions, flags.corruption_fraction, \n",
    "                                              cluster_names, \"test\", flags.DATA_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((\"There are %s genomes and %s features in the training dataset\") % \n",
    "#       (train_data.shape[0],int(train_data.shape[1]/2)))\n",
    "\n",
    "# print((\"There are %s genomes and %s features in the test dataset\") % \n",
    "#       (test_data.shape[0],int(test_data.shape[1]/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if flags.cirriculum:\n",
    "#     loaders = util.cirriculum_load(train_data, test_data, flags.batch_size, \n",
    "#                            flags.batch_size, cluster_names)\n",
    "# else:\n",
    "#     loaders = util.dataloaders(train_data, test_data, flags.batch_size, \n",
    "#                                flags.batch_size, cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from skorch.dataset import CVSplit\n",
    "# from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = int(train_data.shape[1]/2)\n",
    "# X = train_data[:,:num_features] # corrupted genomes in first half of matrix columns\n",
    "# y = train_data[:,num_features:] # uncorrupted in second half of matrix columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dataloader with folds \n",
    "# train_ds = TensorDataset(X, y)\n",
    "# splitter = CVSplit(cv=3)\n",
    "# train_dl = splitter(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_dl), type(train_dl[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# k = 3\n",
    "# idx_genomes = [i for i in range(len(X))]\n",
    "# num_test = int(len(idx_genomes) / k )\n",
    "# num_train = len(idx_genomes) - num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_idx = np.random.choice(idx_genomes, num_test, replace=False)\n",
    "# train_idx = list(set(idx_genomes) - set(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = X[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = train_dl[0]\n",
    "# cv_set = train_dl[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14130"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = int(train_data.shape[1]/2) # Number of features in the entire dataset (train + test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=7065, out_features=3532, bias=True)\n",
      "    (1): Linear(in_features=3532, out_features=1766, bias=True)\n",
      "    (2): Linear(in_features=1766, out_features=1177, bias=True)\n",
      "    (3): Linear(in_features=1177, out_features=1766, bias=True)\n",
      "    (4): Linear(in_features=1766, out_features=3532, bias=True)\n",
      "    (5): Linear(in_features=3532, out_features=7065, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define the network\n",
    "model = models.AutoEncoder(num_features, 6)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_idx 0 3164000.0\n",
      "batch_idx 1 3184500.0\n",
      "batch_idx 2 3198500.0\n",
      "batch_idx 3 3159300.0\n",
      "batch_idx 4 3204051.0\n",
      "batch_idx 5 18199942.0\n",
      "batch_idx 6 2638798.75\n",
      "batch_idx 7 3220659.75\n",
      "batch_idx 8 3085895.5\n",
      "batch_idx 9 3330005.5\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "for epoch in range(1):\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    model.train()\n",
    "    batch_size = 32\n",
    "    loaders = trainable.cv_dataloader(batch_size, num_features, 10)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=0.01,\n",
    "        weight_decay=0.1\n",
    "        )\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    \n",
    "    \n",
    "    # enumerate batches in epoch\n",
    "    for batch_idx, (data, target) in enumerate(loaders[\"train\"]):\n",
    "\n",
    "        if batch_idx > 9: break\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(\"batch_idx\", batch_idx, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vars = {\"batch_size\": 32, #tune.grid_search([32, 64]), # [32, 64, 128, 256]\n",
    "              \"num_epochs\": flags.num_epochs,\n",
    "              \"replacement_threshold\": flags.replacement_threshold,\n",
    "              \"kfolds\": flags.kfolds,\n",
    "              \"lr\": tune.grid_search([0.1, 0.0001]),\n",
    "              \"weight_decay\": 0.01, #tune.grid_search([0.01, 0.00001]),\n",
    "              \"nn_layers\": tune.grid_search([6,8])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:22:15,906\tINFO resource_spec.py:212 -- Starting Ray with 8.74 GiB memory available for workers and up to 4.39 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-07-09 11:22:16,391\tINFO services.py:1170 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.2.23',\n",
       " 'raylet_ip_address': '192.168.2.23',\n",
       " 'redis_address': '192.168.2.23:56511',\n",
       " 'object_store_address': '/tmp/ray/session_2020-07-09_11-22-15_787695_80208/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-07-09_11-22-15_787695_80208/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-07-09_11-22-15_787695_80208'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init(local_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:38:15,858\tINFO trainable.py:217 -- Getting current IP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:38:31,127\tWARNING util.py:137 -- The `start_trial` operation took 15.296487808227539 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.5995521444497024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 2/12 CPUs, 0/0 GPUs, 0.0/8.74 GiB heap, 0.0/3.03 GiB objects<br>Result logdir: /Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1<br>Number of trials: 8 (7 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  nn_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00001</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:38:31,145\tINFO trainable.py:217 -- Getting current IP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:38:45,262\tWARNING util.py:137 -- The `start_trial` operation took 14.126341342926025 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.31932410215133855\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.5/32.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 4/12 CPUs, 0/0 GPUs, 0.0/8.74 GiB heap, 0.0/3.03 GiB objects<br>Result logdir: /Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1<br>Number of trials: 8 (6 PENDING, 2 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  nn_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00002</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:38:45,282\tINFO trainable.py:217 -- Getting current IP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:39:00,404\tWARNING util.py:137 -- The `start_trial` operation took 15.134517908096313 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.5884612574506558\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.4/32.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 6/12 CPUs, 0/0 GPUs, 0.0/8.74 GiB heap, 0.0/3.03 GiB objects<br>Result logdir: /Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1<br>Number of trials: 8 (5 PENDING, 3 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  nn_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00003</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:39:00,488\tINFO trainable.py:217 -- Getting current IP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:39:18,292\tWARNING util.py:137 -- The `start_trial` operation took 17.856355905532837 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.322881657915541\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.7/32.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 8/12 CPUs, 0/0 GPUs, 0.0/8.74 GiB heap, 0.0/3.03 GiB objects<br>Result logdir: /Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1<br>Number of trials: 8 (4 PENDING, 4 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  nn_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00003</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00004</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:39:18,312\tINFO trainable.py:217 -- Getting current IP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:39:36,936\tWARNING util.py:137 -- The `start_trial` operation took 18.637702703475952 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.5644379376981854\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.5/32.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 10/12 CPUs, 0/0 GPUs, 0.0/8.74 GiB heap, 0.0/3.03 GiB objects<br>Result logdir: /Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1<br>Number of trials: 8 (3 PENDING, 5 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  nn_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00003</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00004</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00005</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:39:36,973\tINFO trainable.py:217 -- Getting current IP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:39:52,444\tWARNING util.py:137 -- The `start_trial` operation took 15.495208024978638 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.3322516271881666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.8/32.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/8.74 GiB heap, 0.0/3.03 GiB objects<br>Result logdir: /Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1<br>Number of trials: 8 (2 PENDING, 6 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  nn_layers</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00000</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00001</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00002</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00003</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00004</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00005</td><td>RUNNING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td></tr>\n",
       "<tr><td>train_AE_00006</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td></tr>\n",
       "<tr><td>train_AE_00007</td><td>PENDING </td><td>     </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:39:52,457\tWARNING ray_trial_executor.py:415 -- Over the last 60 seconds, the Tune event loop has been backlogged processing new results. Consider increasing your period of result reporting to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_00000:\n",
      "  date: 2020-07-09_11-38-31\n",
      "  done: false\n",
      "  experiment_id: 9ce4c544889c407f96d27175673e40c4\n",
      "  experiment_tag: 0_lr=0.1,nn_layers=6\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.23\n",
      "  pid: 80208\n",
      "  test_f1: 0.5995521444497024\n",
      "  test_loss: 3175500.0\n",
      "  time_since_restore: 15.266225099563599\n",
      "  time_this_iter_s: 15.266225099563599\n",
      "  time_total_s: 15.266225099563599\n",
      "  timestamp: 1594309111\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.29197380787193256\n",
      "  train_loss: 158866.671875\n",
      "  training_iteration: 1\n",
      "  trial_id: '00000'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:40:06,683\tWARNING util.py:137 -- The `process_trial` operation took 14.222771167755127 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.591020224215779\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.4/32.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/8.74 GiB heap, 0.0/3.03 GiB objects<br>Result logdir: /Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1<br>Number of trials: 8 (2 PENDING, 6 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  nn_layers</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00000</td><td>RUNNING </td><td>192.168.2.23:80208</td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2662</td></tr>\n",
       "<tr><td>train_AE_00001</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00002</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00003</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00004</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00005</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00006</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00007</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_00005:\n",
      "  date: 2020-07-09_11-39-52\n",
      "  done: false\n",
      "  experiment_id: eabf8e9b808c48db932b404b2c64a061\n",
      "  experiment_tag: 5_lr=0.0001,nn_layers=6\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.23\n",
      "  pid: 80208\n",
      "  test_f1: 0.3322516271881666\n",
      "  test_loss: 152357.46875\n",
      "  time_since_restore: 15.468389987945557\n",
      "  time_this_iter_s: 15.468389987945557\n",
      "  time_total_s: 15.468389987945557\n",
      "  timestamp: 1594309192\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.2821531493498646\n",
      "  train_loss: 157891.25\n",
      "  training_iteration: 1\n",
      "  trial_id: '00005'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:40:14,311\tWARNING util.py:137 -- The `process_trial` operation took 7.6201090812683105 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 0.6034795316218932\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/8.74 GiB heap, 0.0/3.03 GiB objects<br>Result logdir: /Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1<br>Number of trials: 8 (2 PENDING, 6 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  nn_layers</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00000</td><td>RUNNING </td><td>192.168.2.23:80208</td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2662</td></tr>\n",
       "<tr><td>train_AE_00001</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00002</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00003</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00004</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00005</td><td>RUNNING </td><td>192.168.2.23:80208</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4684</td></tr>\n",
       "<tr><td>train_AE_00006</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00007</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_00002:\n",
      "  date: 2020-07-09_11-39-00\n",
      "  done: false\n",
      "  experiment_id: 2fb0edae845d46ab9a480aa001da45a5\n",
      "  experiment_tag: 2_lr=0.1,nn_layers=8\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.23\n",
      "  pid: 80208\n",
      "  test_f1: 0.5884612574506558\n",
      "  test_loss: 2999800.0\n",
      "  time_since_restore: 15.102816820144653\n",
      "  time_this_iter_s: 15.102816820144653\n",
      "  time_total_s: 15.102816820144653\n",
      "  timestamp: 1594309140\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.26146570824273047\n",
      "  train_loss: 159152.515625\n",
      "  training_iteration: 1\n",
      "  trial_id: '00002'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:40:23,965\tWARNING util.py:137 -- The `process_trial` operation took 9.65015196800232 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.3/32.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/8.74 GiB heap, 0.0/3.03 GiB objects<br>Result logdir: /Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1<br>Number of trials: 8 (2 PENDING, 6 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  nn_layers</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00000</td><td>RUNNING </td><td>192.168.2.23:80208</td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2662</td></tr>\n",
       "<tr><td>train_AE_00001</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00002</td><td>RUNNING </td><td>192.168.2.23:80208</td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1028</td></tr>\n",
       "<tr><td>train_AE_00003</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00004</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00005</td><td>RUNNING </td><td>192.168.2.23:80208</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4684</td></tr>\n",
       "<tr><td>train_AE_00006</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00007</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:40:23,980\tERROR trial_runner.py:519 -- Trial train_AE_00002: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::WrappedFunc.train()\u001b[39m (pid=80208, ip=192.168.2.23)\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 261, in train\n",
      "    result = self._train()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 199, in _train\n",
      "    block=True, timeout=RESULT_FETCH_TIMEOUT)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/queue.py\", line 179, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 300, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::WrappedFunc.train()\u001b[39m (pid=80208, ip=192.168.2.23)\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 466, in ray._raylet.execute_task\n",
      "ray.exceptions.RayCancellationError: Task: TaskID(ffffffffffffffffffffffff0100) was cancelled\n",
      "2020-07-09 11:40:24,019\tINFO trainable.py:217 -- Getting current IP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 32\n",
      "f1 0.5633717274774457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:40:30,001\tWARNING util.py:137 -- The `start_trial` operation took 5.996563911437988 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 18.8/32.0 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
       "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None | Iter 1.000: None<br>Resources requested: 12/12 CPUs, 0/0 GPUs, 0.0/8.74 GiB heap, 0.0/3.03 GiB objects<br>Result logdir: /Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1<br>Number of trials: 8 (1 ERROR, 1 PENDING, 6 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th>status  </th><th>loc               </th><th style=\"text-align: right;\">    lr</th><th style=\"text-align: right;\">  nn_layers</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00000</td><td>RUNNING </td><td>192.168.2.23:80208</td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.2662</td></tr>\n",
       "<tr><td>train_AE_00001</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00002</td><td>ERROR   </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.1028</td></tr>\n",
       "<tr><td>train_AE_00003</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00004</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00005</td><td>RUNNING </td><td>192.168.2.23:80208</td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         15.4684</td></tr>\n",
       "<tr><td>train_AE_00006</td><td>RUNNING </td><td>                  </td><td style=\"text-align: right;\">0.1   </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "<tr><td>train_AE_00007</td><td>PENDING </td><td>                  </td><td style=\"text-align: right;\">0.0001</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name    </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                    </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_AE_00002</td><td style=\"text-align: right;\">           1</td><td>/Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/TUNE_RESULT_DIR/exp_1/train_AE_2_lr=0.1,nn_layers=8_2020-07-09_11-38-45b8ze7tz5/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:40:30,016\tERROR trial_runner.py:519 -- Trial train_AE_00006: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::WrappedFunc.train()\u001b[39m (pid=80208, ip=192.168.2.23)\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 261, in train\n",
      "    result = self._train()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 199, in _train\n",
      "    block=True, timeout=RESULT_FETCH_TIMEOUT)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/queue.py\", line 179, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 300, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::WrappedFunc.train()\u001b[39m (pid=80208, ip=192.168.2.23)\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 466, in ray._raylet.execute_task\n",
      "ray.exceptions.RayCancellationError: Task: TaskID(ffffffffffffffffffffffff0100) was cancelled\n",
      "2020-07-09 11:40:30,058\tINFO trainable.py:217 -- Getting current IP.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size 32\n",
      "Result for train_AE_00003:\n",
      "  date: 2020-07-09_11-39-18\n",
      "  done: false\n",
      "  experiment_id: 669ac964867040f7b81ff5dd99798811\n",
      "  experiment_tag: 3_lr=0.0001,nn_layers=8\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.23\n",
      "  pid: 80208\n",
      "  test_f1: 0.322881657915541\n",
      "  test_loss: 153437.0625\n",
      "  time_since_restore: 17.795568704605103\n",
      "  time_this_iter_s: 17.795568704605103\n",
      "  time_total_s: 17.795568704605103\n",
      "  timestamp: 1594309158\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.29502811018450087\n",
      "  train_loss: 158562.828125\n",
      "  training_iteration: 1\n",
      "  trial_id: '00003'\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-07-09 11:40:30,507\tERROR trial_runner.py:519 -- Trial train_AE_00007: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::WrappedFunc.train()\u001b[39m (pid=80208, ip=192.168.2.23)\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 261, in train\n",
      "    result = self._train()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 199, in _train\n",
      "    block=True, timeout=RESULT_FETCH_TIMEOUT)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/queue.py\", line 179, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 300, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::WrappedFunc.train()\u001b[39m (pid=80208, ip=192.168.2.23)\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 466, in ray._raylet.execute_task\n",
      "ray.exceptions.RayCancellationError: Task: TaskID(ffffffffffffffffffffffff0100) was cancelled\n",
      "2020-07-09 11:40:30,518\tERROR trial_runner.py:519 -- Trial train_AE_00003: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/trial_runner.py\", line 467, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py\", line 431, in fetch_result\n",
      "    result = ray.get(trial_future[0], DEFAULT_GET_TIMEOUT)\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/worker.py\", line 1515, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError: \u001b[36mray::WrappedFunc.train()\u001b[39m (pid=80208, ip=192.168.2.23)\n",
      "  File \"python/ray/_raylet.pyx\", line 417, in ray._raylet.execute_task.function_executor\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/trainable.py\", line 261, in train\n",
      "    result = self._train()\n",
      "  File \"/usr/local/lib/python3.7/site-packages/ray/tune/function_runner.py\", line 199, in _train\n",
      "    block=True, timeout=RESULT_FETCH_TIMEOUT)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/queue.py\", line 179, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/threading.py\", line 300, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\u001b[36mray::WrappedFunc.train()\u001b[39m (pid=80208, ip=192.168.2.23)\n",
      "  File \"python/ray/_raylet.pyx\", line 459, in ray._raylet.execute_task\n",
      "  File \"python/ray/_raylet.pyx\", line 466, in ray._raylet.execute_task\n",
      "ray.exceptions.RayCancellationError: Task: TaskID(ffffffffffffffffffffffff0100) was cancelled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_AE_00004:\n",
      "  date: 2020-07-09_11-39-36\n",
      "  done: false\n",
      "  experiment_id: 120fb477ad66449ca9fc3748fb24a37f\n",
      "  experiment_tag: 4_lr=0.1,nn_layers=6\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.23\n",
      "  pid: 80208\n",
      "  test_f1: 0.5644379376981854\n",
      "  test_loss: 3028700.0\n",
      "  time_since_restore: 18.62154221534729\n",
      "  time_this_iter_s: 18.62154221534729\n",
      "  time_total_s: 18.62154221534729\n",
      "  timestamp: 1594309176\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.26497840955883006\n",
      "  train_loss: 158402.46875\n",
      "  training_iteration: 1\n",
      "  trial_id: '00004'\n",
      "  \n",
      "Result for train_AE_00001:\n",
      "  date: 2020-07-09_11-38-45\n",
      "  done: false\n",
      "  experiment_id: 3a8e48ffe70b48219976ad892b640dde\n",
      "  experiment_tag: 1_lr=0.0001,nn_layers=6\n",
      "  hostname: natashas-MacBook-Pro.local\n",
      "  iterations_since_restore: 1\n",
      "  node_ip: 192.168.2.23\n",
      "  pid: 80208\n",
      "  test_f1: 0.31932410215133855\n",
      "  test_loss: 152894.234375\n",
      "  time_since_restore: 14.113343000411987\n",
      "  time_this_iter_s: 14.113343000411987\n",
      "  time_total_s: 14.113343000411987\n",
      "  timestamp: 1594309125\n",
      "  timesteps_since_restore: 0\n",
      "  train_f1: 0.27964800816153007\n",
      "  train_loss: 158196.546875\n",
      "  training_iteration: 1\n",
      "  trial_id: '00001'\n",
      "  \n",
      "f1 0.5821648756764558\n"
     ]
    }
   ],
   "source": [
    "analysis = tune.run(\n",
    "    trainable.train_AE, \n",
    "    name=\"exp_1\",\n",
    "    config=train_vars, \n",
    "    verbose=2, \n",
    "    resources_per_trial={\n",
    "            \"cpu\": 2,\n",
    "            \"gpu\": 0\n",
    "    },\n",
    "    num_samples=2,\n",
    "    scheduler=ASHAScheduler(metric=\"test_f1\", mode=\"max\", grace_period=1, time_attr=\"n_batch\"),\n",
    "    local_dir=flags.SAVE_FP+\"TUNE_RESULT_DIR\"\n",
    "    )\n",
    "\n",
    "print(\"Best config is:\", analysis.get_best_config(metric=\"test_f1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in train_vars:\n",
    "    if isinstance(train_vars[i], dict):\n",
    "        print(\"Best \"+i+\":\", analysis.get_best_config(metric=\"test_f1\")[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.dataframe()[\"logdir\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "# train_losses, test_losses, train_f1_scores, test_f1_scores = train_test.train_model(loaders, \n",
    "#         model, flags.num_epochs, flags.print_every,\n",
    "#         flags.SAVE_FP, flags.replacement_threshold, cluster_names, flags.cirriculum, train_data[:,:len(cluster_names)],\n",
    "#         search_space)\n",
    "#train_losses, test_losses, train_f1_scores, test_f1_scores = train_test.train_model(train_vars, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model performance\n",
    "# perf_lc = data_viz.learning_curve(train_f1_scores, test_f1_scores, \"performance\", flags.cirriculum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model performance\n",
    "# optim_lc = data_viz.learning_curve(train_losses, test_losses, \"optimization\", flags.cirriculum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first convert test_data from subset -> tensor, split corrupt vs target sets\n",
    "# tensor_test_data = torch.tensor([i.numpy() for i in test_data]).float()\n",
    "# corrupt_test_data = tensor_test_data[:,:len(cluster_names)]\n",
    "# target = tensor_test_data[:,len(cluster_names):].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate probabilities for ROC curve\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     y_probas = model(corrupt_test_data) # predicted probabilities generated by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc = data_viz.my_roc_curve(target, y_probas.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util.log_results(roc, optim_lc, perf_lc, flags, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create embeddings for test set\n",
    "# #uncorrupt_test_data = tensor_test_data[:,len(cluster_names):]\n",
    "# #tensor_test_data = torch.tensor([i.numpy() for i in test_data]).float()\n",
    "# embeddings = train_test.generate_embeddings(model, corrupt_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.plot_tSNE(embeddings, test_data, num_to_genome, genome_to_tax, test_tax_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tSNE for corrupted genomes passed through untrained model\n",
    "# untrained_model = models.AutoEncoder(len(cluster_names))\n",
    "# untr_embeddings = train_test.generate_embeddings(untrained_model, corrupt_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.plot_tSNE(untr_embeddings, test_data, num_to_genome, genome_to_tax, test_tax_dict)\n",
    "# data_viz.plot_tSNE(untr_embeddings, test_data, num_to_genome, genome_to_tax, genome_idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate model and compare against baselines\n",
    "# # Get corrupted input set, target set, and predictions set (binarized to 1's and 0's)\n",
    "# #corrupt_test_data = tensor_test_data[:,:len(cluster_names)]\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     pred = model.forward(corrupt_test_data).detach().numpy()\n",
    "# b_pred = train_test.binarize(pred, flags.replacement_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate confusion matrix\n",
    "# cm = evaluate.dom_confusion_matrix(b_pred, target, num_to_genome, genome_to_tax, test_tax_dict, genome_idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util.log_results(roc, optim_lc, perf_lc, flags, model, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baseline 1: untrained DAE\n",
    "# # Generate predictions using an untrained DAE model\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     untr_pred = untrained_model.forward(corrupt_test_data).detach().numpy()\n",
    "# untr_b_preds = train_test.binarize(untr_pred, flags.replacement_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if os.path.isfile(flags.DATA_FP+\"rand_b_pred.pt\"):\n",
    "# #     print(\"Loading random predictions from file\")\n",
    "# #     rand_b_pred = torch.load(flags.DATA_FP+\"rand_b_pred.pt\")\n",
    "# # else: \n",
    "# #     # This is slow\n",
    "# #     print(\"Generating random predictions, this will take a while (~30 min)\")\n",
    "# #     rand_b_pred = evaluate.generate_baseline(num_features, train_data, \n",
    "# #                                              corrupt_test_data, \"base_random\", cluster_names)\n",
    "# #     torch.save(rand_b_pred, flags.DATA_FP+\"rand_b_pred.pt\")\n",
    "\n",
    "# rand_b_pred = evaluate.generate_baseline(num_features, train_data, \n",
    "#                                          corrupt_test_data, \"base_random\", cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(rand_b_pred, flags.DATA_FP+\"rand_b_pred.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if os.path.isfile(flags.DATA_FP+\"smart_b_pred.pt\"):\n",
    "# #     print(\"Loading smart random predictions from file\")\n",
    "# #     smart_b_pred = torch.load(flags.DATA_FP+\"smart_b_pred.pt\")\n",
    "# # else:\n",
    "# #     print(\"Generating smart random predictions, this will take a while (~30 min)\")\n",
    "# #     smart_b_pred = evaluate.generate_baseline(num_features, train_data, \n",
    "# #                                           corrupt_test_data, \"smart_random\", cluster_names)\n",
    "# #     torch.save(smart_b_pred, flags.DATA_FP+\"smart_b_pred.pt\")\n",
    "\n",
    "# smart_b_pred = evaluate.generate_baseline(num_features, train_data, \n",
    "#                                       corrupt_test_data, \"smart_random\", cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(smart_b_pred, flags.DATA_FP+\"smart_b_pred.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.sum(smart_b_pred == rand_b_pred), np.sum(smart_b_pred != rand_b_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# hs = evaluate.hamming(target, b_pred)\n",
    "# hs_stats = [round(sum(hs)/len(hs),2), round(min(hs),2), round(max(hs),2)]\n",
    "\n",
    "# untr_hs = evaluate.hamming(target, untr_b_preds)\n",
    "# untr_hs_stats = [round(sum(untr_hs)/len(untr_hs),2), round(min(untr_hs),2), round(max(untr_hs),2)]\n",
    "\n",
    "# rand_hs = evaluate.hamming(target, rand_b_pred)\n",
    "# rand_hs_stats = [round(sum(rand_hs)/len(rand_hs),2), round(min(rand_hs),2), round(max(rand_hs),2)]\n",
    "\n",
    "# smart_hs = evaluate.hamming(target, smart_b_pred)\n",
    "# smart_hs_stats = [round(sum(smart_hs)/len(smart_hs),2), round(min(smart_hs),2), round(max(smart_hs),2)]\n",
    "\n",
    "\n",
    "# hamming_df = pd.DataFrame([hs_stats, untr_hs_stats, rand_hs_stats, smart_hs_stats], columns=['mean', 'min', 'max'], \n",
    "#                             index=[\"DAE trained\", \"DAE untrained\", \"Random chance\", \"Smart random chance\"])\n",
    "# hamming_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
