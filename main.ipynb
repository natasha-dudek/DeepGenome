{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically upload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "#import pickle\n",
    "from ray import tune\n",
    "import ConfigSpace as CS\n",
    "from ray.tune.suggest.bohb import TuneBOHB\n",
    "from ray.tune.schedulers import HyperBandForBOHB\n",
    "import torch\n",
    "import argparse # for ray distributed training\n",
    "\n",
    "\n",
    "from genome_embeddings import data_viz\n",
    "from genome_embeddings import evaluate\n",
    "from genome_embeddings import models\n",
    "from genome_embeddings import train_test\n",
    "from genome_embeddings import util\n",
    "from genome_embeddings import trainable # import before ray (?)\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\"rm file_out\")\n",
    "os.system(\"rm file_err\")\n",
    "\n",
    "sys.stdout = open('file_out', 'w')\n",
    "sys.stderr = open('file_err', 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = Namespace(\n",
    "    DATA_FP = '/home/ndudek/projects/def-dprecup/ndudek/',\n",
    "    SAVE_FP = '/home/ndudek/projects/def-dprecup/ndudek/',\n",
    "    num_epochs = 2,\n",
    "    num_cpus=1)\n",
    "\n",
    "# settings = Namespace(\n",
    "#     DATA_FP = '/Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/data/', \n",
    "#     SAVE_FP = '/Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/genome_embeddings/',\n",
    "#     num_epochs = 2,\n",
    "#     num_cpus=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = Namespace(\n",
    "    KEGG_FP = '/Users/natasha/Desktop/mcgill_postdoc/ncbi_genomes/kegg_dataset/',\n",
    "    data_source = 'kegg', #['get_homologues' | 'kegg']\n",
    "    n_test = 0.1, # train-test split, n * 100 = % of data that goes into test set (e.g.: 0.1 -> 10%)\n",
    "    batch_size = 128,\n",
    "    lr = 1e-3,\n",
    "    kfolds = 10, # number of folds for cross-validation\n",
    "    print_every = 50, # print loss every n batches during training (5)\n",
    "    replacement_threshold = 0.5, # probability over which binarizer converts to a 1\n",
    "    num_corruptions = 100, # number of corrupted versions of a genome to produce\n",
    "    corruption_fraction = 0.5, # fraction of genes to retain during corruption process\n",
    "    phy_mode = \"bacteria_only\", # training with only bacteria vs also euk/arch\n",
    "    cirriculum = False, # implement cirriculum learning based on gene count\n",
    "    rare_threshold = 10, # drop features that occur fewer than this times in training ds \n",
    "    weight_decay=0.1 # L2 regularization\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done loading modules and setting Namespace variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration + preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # First create genome representations (very slow)\n",
    "# # Each genome is a list of KO's and/or KEGG modules\n",
    "# if os.path.isfile(settings.DATA_FP+'genome_to_mod.csv'):\n",
    "#     print(\"Genome representations already exist\")\n",
    "# else:\n",
    "#     genome_rep.genome_kos(flags.KEGG_FP)\n",
    "#     print(\"Must generate genome representations from scratch. This will take several hours.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, cluster_names = util.load_data(settings.DATA_FP, flags.data_source)\n",
    "genome_to_tax = util.genome_to_tax(df)\n",
    "np.save(settings.DATA_FP+'genome_to_tax.npy', genome_to_tax) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.tax_distrib(df, genome_to_tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.module_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.genes_per_genome(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# genome_to_tax = util.genome_to_tax(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_orig = pd.read_csv(settings.DATA_FP+\"uncorrupted_train_balanced.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_genomes = list(train_orig.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train-test sets in a phylogenetically balanced manner \n",
    "if os.path.isfile(settings.DATA_FP+'uncorrupted_train_balanced.csv'):\n",
    "    print(\"Train-test split already exists, loading from file\")\n",
    "    train_orig = pd.read_csv(settings.DATA_FP+\"uncorrupted_train_balanced.csv\", index_col=0)    \n",
    "    test_orig = pd.read_csv(settings.DATA_FP+\"uncorrupted_test_balanced.csv\", index_col=0)    \n",
    "\n",
    "else:\n",
    "    # Create dict mapping each genome to a unique numerical ID\n",
    "    genome_to_num ={}\n",
    "    for i,genome in enumerate(df.index):\n",
    "        genome_to_num[genome] = i\n",
    "\n",
    "    num_to_genome = {v: k for k, v in genome_to_num.items()}\n",
    "        \n",
    "    print(\"Generating train-test split\")\n",
    "    train_orig, test_orig = util.balanced_split(df, flags.n_test, genome_to_tax, \n",
    "                                                num_to_genome, settings.DATA_FP)    \n",
    "    train_orig.to_csv(settings.DATA_FP+'uncorrupted_train_balanced.csv')\n",
    "    test_orig.to_csv(settings.DATA_FP+'uncorrupted_test_balanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.hist_prob_ko(train_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if flags.phy_mode == \"bacteria_only\":\n",
    "    train_genomes = train_orig.index.to_list()\n",
    "    test_genomes = test_orig.index.to_list()\n",
    "    \n",
    "    unf_train_data, train_tax_dict = util.bacteria_only(train_orig, train_genomes, genome_to_tax)\n",
    "    unf_test_data, test_tax_dict = util.bacteria_only(test_orig, test_genomes, genome_to_tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rare features from train + test datasets\n",
    "# Rare = fewer than n occurences in training dataset\n",
    "# Last argument specifies n, set to correspond to 1% of genomes (3432 genomes -> n = 34)\n",
    "# Remove genes occuring in <1.1% of genomes ---> extra 0.1 is to make there be an even number of features\n",
    "#     An even number of features is essential for having the autoencoder layers work out properly\n",
    "train_data, test_data, cluster_names = util.remove_rare(unf_train_data, unf_test_data, \n",
    "                                                        cluster_names, unf_train_data.shape[0]*0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupted genomes already exist\n"
     ]
    }
   ],
   "source": [
    "# Produce corrupted genomes\n",
    "# Could eventually do re-sampling / extra-corrupting to have more examples of \"rare\" genome types\n",
    "#    e.g.: those from underrepresented groups M00003   \n",
    "\n",
    "if os.path.isfile(settings.DATA_FP+'corrupted_train_07-17-20.pt'):\n",
    "    print(\"Corrupted genomes already exist\")\n",
    "    train_data = torch.load(settings.DATA_FP+\"corrupted_train_07-17-20.pt\")\n",
    "    test_data = torch.load(settings.DATA_FP+\"corrupted_test_07-17-20.pt\")\n",
    "    genome_idx_train = torch.load(settings.DATA_FP+\"genome_idx_train_07-17-20.pt\")\n",
    "    genome_idx_test = torch.load(settings.DATA_FP+\"genome_idx_test_07-17-20.pt\")\n",
    "else:\n",
    "    print(\"Generating corrupted dataset from scratch with\",flags.num_corruptions,\"corrupted versions of each genome\")\n",
    "    train_data, genome_idx_train = util.corrupt(train_data, flags.num_corruptions, flags.corruption_fraction, \n",
    "                                                    cluster_names, \"train\", settings.DATA_FP)\n",
    "    print(\"Finished training data, starting test\")\n",
    "    test_data, genome_idx_test = util.corrupt(test_data, flags.num_corruptions, flags.corruption_fraction, \n",
    "                                                  cluster_names, \"test\", settings.DATA_FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout.flush()\n",
    "sys.stderr.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np # this is slooooow\n",
    "#np.savetxt(settings.DATA_FP+\"corrupted_train_1407.txt\", train_data.numpy())\n",
    "#np.savetxt(settings.DATA_FP+\"corrupted_test_1407.txt\", test_data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((\"There are %s genomes and %s features in the training dataset\") % \n",
    "#       (train_data.shape[0],int(train_data.shape[1]/2)))\n",
    "\n",
    "# print((\"There are %s genomes and %s features in the test dataset\") % \n",
    "#       (test_data.shape[0],int(test_data.shape[1]/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_features = int(train_data.shape[1]/2) # Number of features in the entire dataset (train + test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (layers): ModuleList(\n",
      "    (0): Linear(in_features=7065, out_features=13, bias=True)\n",
      "    (1): Linear(in_features=13, out_features=4, bias=True)\n",
      "    (2): Linear(in_features=4, out_features=13, bias=True)\n",
      "    (3): Linear(in_features=13, out_features=7065, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# # define the network\n",
    "# model = models.AutoEncoder(num_features, 2)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout.flush()\n",
    "sys.stderr.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_space = CS.ConfigurationSpace()\n",
    "\n",
    "config_space.add_hyperparameter(\n",
    "    CS.CategoricalHyperparameter(name='nn_layers', choices=[1, 2])) #, 3, 4])) \n",
    "\n",
    "config_space.add_hyperparameter(\n",
    "    CS.CategoricalHyperparameter(name='batch_size', choices=[32])) #, 64, 128, 256]))\n",
    "\n",
    "#Optimizer = Adam -- LR less important\n",
    "config_space.add_hyperparameter(\n",
    "    CS.UniformFloatHyperparameter('lr', lower=1e-4, upper=1e-1, log=True))\n",
    "\n",
    "config_space.add_hyperparameter(\n",
    "    CS.UniformFloatHyperparameter('weight_decay', lower=1e-5, upper=1e-2, log=True))\n",
    "\n",
    "algo = TuneBOHB(\n",
    "    config_space, max_concurrent=4, metric='test_f1', mode='max')\n",
    "\n",
    "bohb = HyperBandForBOHB(\n",
    "    time_attr='training_iteration',\n",
    "    metric='test_f1',\n",
    "    mode='max',\n",
    "    max_t=100, \n",
    "    reduction_factor=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = 2000 * 1024 * 1024\n",
    "object_store_memory = 200 * 1024 * 1024\n",
    "driver_object_store_memory=100 * 1024 * 1024\n",
    "ray.shutdown()\n",
    "ray.init(local_mode=True, memory=memory, \n",
    "        object_store_memory=object_store_memory,\n",
    "        driver_object_store_memory=driver_object_store_memory,\n",
    "        num_cpus=1)\n",
    "\n",
    "# redis_password = sys.argv[1]\n",
    "# num_cpus = int(sys.argv[2])\n",
    "\n",
    "# ray.init(address=os.environ[\"ip_head\"], redis_password=redis_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"num_workers\": 1,\n",
    "         \"num_epochs\":settings.num_epochs,\n",
    "         \"kfolds\":flags.kfolds,\n",
    "         \"replacement_threshold\": flags.replacement_threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    trainable.train_AE, \n",
    "    name=\"exp_1\",\n",
    "    config=config,\n",
    "    search_alg=algo,\n",
    "    verbose=2, \n",
    "    resources_per_trial={\n",
    "            \"cpu\": settings.num_cpus,\n",
    "            \"gpu\": 0\n",
    "    },\n",
    "    num_samples=10,  #BUMP UP TO 1000\n",
    "    scheduler=bohb,\n",
    "    local_dir=settings.SAVE_FP+\"TUNE_RESULT_DIR\",\n",
    "    stop=trainable.EarlyStopping(\"test_f1\") # if search results aren't improving anymore\n",
    "    )\n",
    "\n",
    "#print(\"Best config is:\", analysis.get_best_config(metric=\"test_f1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best config is:\", analysis.get_best_config(metric=\"test_f1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in train_vars:\n",
    "#     if isinstance(train_vars[i], dict):\n",
    "#         print(\"Best \"+i+\":\", analysis.get_best_config(metric=\"test_f1\")[i])\n",
    "for i in config_space:\n",
    "    print(\"Best \"+i+\":\", analysis.get_best_config(metric=\"test_f1\")[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis = tune.run(\n",
    "#     trainable.train_AE, \n",
    "#     name=\"exp_1\",\n",
    "#     config=train_vars, \n",
    "#     verbose=2, \n",
    "#     resources_per_trial={\n",
    "#             \"cpu\": 2,\n",
    "#             \"gpu\": 0\n",
    "#     },\n",
    "#     num_samples=2,\n",
    "#     scheduler=ASHAScheduler(metric=\"test_f1\", mode=\"max\", grace_period=1, time_attr=\"n_batch\"),\n",
    "#     local_dir=settings.SAVE_FP+\"TUNE_RESULT_DIR\"\n",
    "#     )\n",
    "\n",
    "# print(\"Best config is:\", analysis.get_best_config(metric=\"test_f1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis.dataframe()[\"logdir\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "# train_losses, test_losses, train_f1_scores, test_f1_scores = train_test.train_model(loaders, \n",
    "#         model, settings.num_epochs, flags.print_every,\n",
    "#         settings.SAVE_FP, flags.replacement_threshold, cluster_names, flags.cirriculum, train_data[:,:len(cluster_names)],\n",
    "#         search_space)\n",
    "#train_losses, test_losses, train_f1_scores, test_f1_scores = train_test.train_model(train_vars, hyperparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model performance\n",
    "# perf_lc = data_viz.learning_curve(train_f1_scores, test_f1_scores, \"performance\", flags.cirriculum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model performance\n",
    "# optim_lc = data_viz.learning_curve(train_losses, test_losses, \"optimization\", flags.cirriculum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # first convert test_data from subset -> tensor, split corrupt vs target sets\n",
    "# tensor_test_data = torch.tensor([i.numpy() for i in test_data]).float()\n",
    "# corrupt_test_data = tensor_test_data[:,:num_features]\n",
    "# target = tensor_test_data[:,num_features:].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate probabilities for ROC curve\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     y_probas = model(corrupt_test_data) # predicted probabilities generated by model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc = data_viz.my_roc_curve(target, y_probas.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util.log_results(roc, optim_lc, perf_lc, flags, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create embeddings for test set\n",
    "# #uncorrupt_test_data = tensor_test_data[:,len(cluster_names):]\n",
    "# #tensor_test_data = torch.tensor([i.numpy() for i in test_data]).float()\n",
    "# embeddings = train_test.generate_embeddings(model, corrupt_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.plot_tSNE(embeddings, test_data, num_to_genome, genome_to_tax, test_tax_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tSNE for corrupted genomes passed through untrained model\n",
    "# untrained_model = models.AutoEncoder(len(cluster_names))\n",
    "# untr_embeddings = train_test.generate_embeddings(untrained_model, corrupt_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_viz.plot_tSNE(untr_embeddings, test_data, num_to_genome, genome_to_tax, test_tax_dict)\n",
    "# data_viz.plot_tSNE(untr_embeddings, test_data, num_to_genome, genome_to_tax, genome_idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate model and compare against baselines\n",
    "# # Get corrupted input set, target set, and predictions set (binarized to 1's and 0's)\n",
    "# #corrupt_test_data = tensor_test_data[:,:len(cluster_names)]\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     pred = model.forward(corrupt_test_data).detach().numpy()\n",
    "# b_pred = train_test.binarize(pred, flags.replacement_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate confusion matrix\n",
    "# cm = evaluate.dom_confusion_matrix(b_pred, target, num_to_genome, genome_to_tax, test_tax_dict, genome_idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util.log_results(roc, optim_lc, perf_lc, flags, model, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Baseline 1: untrained DAE\n",
    "# # Generate predictions using an untrained DAE model\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     untr_pred = untrained_model.forward(corrupt_test_data).detach().numpy()\n",
    "# untr_b_preds = train_test.binarize(untr_pred, flags.replacement_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if os.path.isfile(settings.DATA_FP+\"rand_b_pred.pt\"):\n",
    "# #     print(\"Loading random predictions from file\")\n",
    "# #     rand_b_pred = torch.load(settings.DATA_FP+\"rand_b_pred.pt\")\n",
    "# # else: \n",
    "# #     # This is slow\n",
    "# #     print(\"Generating random predictions, this will take a while (~30 min)\")\n",
    "# #     rand_b_pred = evaluate.generate_baseline(num_features, train_data, \n",
    "# #                                              corrupt_test_data, \"base_random\", cluster_names)\n",
    "# #     torch.save(rand_b_pred, settings.DATA_FP+\"rand_b_pred.pt\")\n",
    "\n",
    "# rand_b_pred = evaluate.generate_baseline(num_features, train_data, \n",
    "#                                          corrupt_test_data, \"base_random\", cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(rand_b_pred, settings.DATA_FP+\"rand_b_pred.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # if os.path.isfile(settings.DATA_FP+\"smart_b_pred.pt\"):\n",
    "# #     print(\"Loading smart random predictions from file\")\n",
    "# #     smart_b_pred = torch.load(settings.DATA_FP+\"smart_b_pred.pt\")\n",
    "# # else:\n",
    "# #     print(\"Generating smart random predictions, this will take a while (~30 min)\")\n",
    "# #     smart_b_pred = evaluate.generate_baseline(num_features, train_data, \n",
    "# #                                           corrupt_test_data, \"smart_random\", cluster_names)\n",
    "# #     torch.save(smart_b_pred, settings.DATA_FP+\"smart_b_pred.pt\")\n",
    "\n",
    "# smart_b_pred = evaluate.generate_baseline(num_features, train_data, \n",
    "#                                       corrupt_test_data, \"smart_random\", cluster_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(smart_b_pred, settings.DATA_FP+\"smart_b_pred.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.sum(smart_b_pred == rand_b_pred), np.sum(smart_b_pred != rand_b_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# hs = evaluate.hamming(target, b_pred)\n",
    "# hs_stats = [round(sum(hs)/len(hs),2), round(min(hs),2), round(max(hs),2)]\n",
    "\n",
    "# untr_hs = evaluate.hamming(target, untr_b_preds)\n",
    "# untr_hs_stats = [round(sum(untr_hs)/len(untr_hs),2), round(min(untr_hs),2), round(max(untr_hs),2)]\n",
    "\n",
    "# rand_hs = evaluate.hamming(target, rand_b_pred)\n",
    "# rand_hs_stats = [round(sum(rand_hs)/len(rand_hs),2), round(min(rand_hs),2), round(max(rand_hs),2)]\n",
    "\n",
    "# smart_hs = evaluate.hamming(target, smart_b_pred)\n",
    "# smart_hs_stats = [round(sum(smart_hs)/len(smart_hs),2), round(min(smart_hs),2), round(max(smart_hs),2)]\n",
    "\n",
    "\n",
    "# hamming_df = pd.DataFrame([hs_stats, untr_hs_stats, rand_hs_stats, smart_hs_stats], columns=['mean', 'min', 'max'], \n",
    "#                             index=[\"DAE trained\", \"DAE untrained\", \"Random chance\", \"Smart random chance\"])\n",
    "# hamming_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout.flush()\n",
    "sys.stderr.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
