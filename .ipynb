{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically upload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import ray\n",
    "from ray import tune\n",
    "import torch\n",
    "\n",
    "from genome_embeddings import corrupt\n",
    "from genome_embeddings import data_viz\n",
    "from genome_embeddings import models\n",
    "from genome_embeddings import pre_process\n",
    "from genome_embeddings import trainable # import before ray (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of bacterial genomes in dataset: 2718\n",
      "Total number of KOs in dataset: 9874\n"
     ]
    }
   ],
   "source": [
    "tla_to_tnum, keepers = pre_process.genomes2include()\n",
    "org_to_kos, n_kos_tot, all_kos = pre_process.load_kos(tla_to_tnum)\n",
    "org_to_mod_to_kos, mod_sets = pre_process.load_mods()\n",
    "\n",
    "all_kos = torch.load(\"/Users/natasha/Desktop/all_kos_2020-09-29.pt\")\n",
    "org_to_mod_to_kos = torch.load(\"/Users/natasha/Desktop/org_to_mod_to_kos_2020-09-29.pt\")\n",
    "train_data = torch.load(\"/Users/natasha/Desktop/kegg_v2_train_2020-09-29.pt\")\n",
    "test_data = torch.load(\"/Users/natasha/Desktop/kegg_v2_test_2020-09-29.pt\")\n",
    "train_genomes = torch.load(\"/Users/natasha/Desktop/kegg_v2_train_genomes_2020-09-29.pt\")\n",
    "test_genomes = torch.load(\"/Users/natasha/Desktop/kegg_v2_test_genomes_2020-09-29.pt\")\n",
    "\n",
    "mod_to_ko_clean = pre_process.clean_kos(mod_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any genomes with fewer than 500 KOs \n",
    "# Esp. important to remove genomes with 0 KOs (n=35)\n",
    "\n",
    "good_idx_train = train_data.sum(axis=1) > 500\n",
    "good_idx_test = test_data.sum(axis=1) > 500\n",
    "train_data = train_data[good_idx_train,:]\n",
    "test_data = test_data[good_idx_test,:]\n",
    "\n",
    "# to numpy for indexing, then back to list for using\n",
    "train_genomes = list(np.array(train_genomes)[good_idx_train])\n",
    "test_genomes = list(np.array(test_genomes)[good_idx_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_load = \"2020-10-16_10mods\"\n",
    "\n",
    "corrupted_train = torch.load(\"/Users/natasha/Desktop/corrupted_train_\"+date_to_load+\".pt\")\n",
    "c_train_genomes = torch.load(\"/Users/natasha/Desktop/c_train_genomes_\"+date_to_load+\".pt\")\n",
    "corrupted_test = torch.load(\"/Users/natasha/Desktop/corrupted_test_\"+date_to_load+\".pt\")\n",
    "c_test_genomes = torch.load(\"/Users/natasha/Desktop/c_test_genomes_\"+date_to_load+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = models.get_noise(train_data.shape[0], train_data.shape[1]*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27900, 19748])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = models.Generator().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = models.Critic().to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (gen): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=59244, out_features=39496, bias=True)\n",
       "      (1): BatchNorm2d(39496, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=39496, out_features=19748, bias=True)\n",
       "      (1): BatchNorm2d(19748, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=19748, out_features=9874, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_losses = []\n",
    "critic_losses = []\n",
    "\n",
    "device = torch.device(\"cpu\") #\"cuda\" if use_cuda else \"cpu\")\n",
    "num_features = int(train_data.shape[1]/2)\n",
    "z_dim = num_features * 6\n",
    "\n",
    "# get model instances, set to train mode\n",
    "gen = models.Generator().to('cpu')\n",
    "crit = models.Critic().to('cpu')\n",
    "gen.train()\n",
    "crit.train()\n",
    "\n",
    "# define optimizers\n",
    "beta_1 = 0.5\n",
    "beta_2 = 0.999\n",
    "lr = 0.001\n",
    "gen_opt = torch.optim.AdamW(gen.parameters(), lr=lr, betas=(beta_1, beta_2), weight_decay=weight_decay)\n",
    "crit_opt = torch.optim.AdamW(crit.parameters(), lr=lr, betas=(beta_1, beta_2), weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader\n",
    "loaders = trainable.cv_dataloader_SINGLE(batch_size, num_features, kfolds, train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # enumerate batches in epoch\n",
    "    for batch_idx, (_, real) in enumerate(loaders[\"train\"]):\n",
    "        cur_batch_size = len(real)\n",
    "        real = real.to(device)\t\t\n",
    "\n",
    "        mean_iteration_critic_loss = 0\n",
    "        for _ in range(crit_repeats):\n",
    "            ### Update critic ###\n",
    "            crit_opt.zero_grad()\n",
    "            fake_noise = get_noise(cur_batch_size, z_dim, device=device)\n",
    "            fake = gen(fake_noise)\n",
    "            crit_fake_pred = crit(fake.detach())\n",
    "            crit_real_pred = crit(real)\n",
    "\n",
    "            epsilon = torch.rand(len(real), 1, 1, 1, device=device, requires_grad=True)\n",
    "            gradient = get_gradient(crit, real, fake.detach(), epsilon)\n",
    "            gp = gradient_penalty(gradient)\n",
    "            crit_loss = get_crit_loss(crit_fake_pred, crit_real_pred, gp, c_lambda)\t\t\t\t\n",
    "            # Keep track of the average critic loss in this batch\n",
    "            mean_iteration_critic_loss += crit_loss.item() / crit_repeats\n",
    "            # Update gradients\n",
    "            crit_loss.backward(retain_graph=True)\n",
    "            # Update optimizer\n",
    "            crit_opt.step()\n",
    "\n",
    "        critic_losses += [mean_iteration_critic_loss]\t\t\t\n",
    "\n",
    "        ### Update generator ###\n",
    "        gen_opt.zero_grad()\n",
    "        fake_noise_2 = get_noise(cur_batch_size, z_dim, device=device)\n",
    "        fake_2 = gen(fake_noise_2)\n",
    "        crit_fake_pred = crit(fake_2)\t\t\t\n",
    "\n",
    "        gen_loss = get_gen_loss(crit_fake_pred)\n",
    "        gen_loss.backward()\t\t\t\n",
    "\n",
    "        # Update the weights\n",
    "        gen_opt.step()\n",
    "\n",
    "        # Keep track of the average generator loss\n",
    "        generator_losses += [gen_loss.item()]\t\t\t\n",
    "\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            train_f1 = f1_score(pred, target, replacement_threshold)\n",
    "            test_loss, test_f1 = cv_vae(model, loaders, replacement_threshold)\n",
    "            train_losses.append(loss.item())\n",
    "            test_losses.append(test_loss.item())\n",
    "            train_f1s.append(train_f1)\n",
    "            test_f1s.append(test_f1)\n",
    "            print(\"epoch\",epoch,\"batch\",batch_idx)\n",
    "            print(\"train_loss\",loss.item(), \"train_f1\",train_f1, \"test_loss\",test_loss.item(), \"test_f1\",test_f1) #, auc_score=auc)\t\n",
    "            model.train()\n",
    "\n",
    "# if memory usage is high, may be able to free up space by calling garbage collect\n",
    "auto_garbage_collect() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
